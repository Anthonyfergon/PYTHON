{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53bd5c91",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#DATA-WRANGLING\" data-toc-modified-id=\"DATA-WRANGLING-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>DATA WRANGLING</a></span></li><li><span><a href=\"#STAGE-1:-Data-Discovery\" data-toc-modified-id=\"STAGE-1:-Data-Discovery-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>STAGE 1: Data Discovery</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Import Libraries</a></span></li><li><span><a href=\"#Define-a-Work-Directory\" data-toc-modified-id=\"Define-a-Work-Directory-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>Define a Work Directory</a></span></li><li><span><a href=\"#Modifying-the-WD-path\" data-toc-modified-id=\"Modifying-the-WD-path-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>Modifying the WD path</a></span></li><li><span><a href=\"#Reading-Files\" data-toc-modified-id=\"Reading-Files-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>Reading Files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-CSV-files\" data-toc-modified-id=\"Read-CSV-files-2.0.4.1\"><span class=\"toc-item-num\">2.0.4.1&nbsp;&nbsp;</span>Read CSV files</a></span></li><li><span><a href=\"#Read-CSV-File-from-External-URL\" data-toc-modified-id=\"Read-CSV-File-from-External-URL-2.0.4.2\"><span class=\"toc-item-num\">2.0.4.2&nbsp;&nbsp;</span>Read CSV File from External URL</a></span></li><li><span><a href=\"#Read_CSV:-Addtitional-Functions:\" data-toc-modified-id=\"Read_CSV:-Addtitional-Functions:-2.0.4.3\"><span class=\"toc-item-num\">2.0.4.3&nbsp;&nbsp;</span>Read_CSV: Addtitional Functions:</a></span></li><li><span><a href=\"#Read-XLSX-files\" data-toc-modified-id=\"Read-XLSX-files-2.0.4.4\"><span class=\"toc-item-num\">2.0.4.4&nbsp;&nbsp;</span>Read XLSX files</a></span></li><li><span><a href=\"#Read-TXT-files\" data-toc-modified-id=\"Read-TXT-files-2.0.4.5\"><span class=\"toc-item-num\">2.0.4.5&nbsp;&nbsp;</span>Read TXT files</a></span></li><li><span><a href=\"#Read-Delimited-files\" data-toc-modified-id=\"Read-Delimited-files-2.0.4.6\"><span class=\"toc-item-num\">2.0.4.6&nbsp;&nbsp;</span>Read Delimited files</a></span></li><li><span><a href=\"#Read-JSON-files\" data-toc-modified-id=\"Read-JSON-files-2.0.4.7\"><span class=\"toc-item-num\">2.0.4.7&nbsp;&nbsp;</span>Read JSON files</a></span></li><li><span><a href=\"#Read-ORC-files\" data-toc-modified-id=\"Read-ORC-files-2.0.4.8\"><span class=\"toc-item-num\">2.0.4.8&nbsp;&nbsp;</span>Read ORC files</a></span></li><li><span><a href=\"#Read-AVRO-files\" data-toc-modified-id=\"Read-AVRO-files-2.0.4.9\"><span class=\"toc-item-num\">2.0.4.9&nbsp;&nbsp;</span>Read AVRO files</a></span></li><li><span><a href=\"#Read-ZIP-files\" data-toc-modified-id=\"Read-ZIP-files-2.0.4.10\"><span class=\"toc-item-num\">2.0.4.10&nbsp;&nbsp;</span>Read ZIP files</a></span></li></ul></li><li><span><a href=\"#Dimensions---df.ndim\" data-toc-modified-id=\"Dimensions---df.ndim-2.0.5\"><span class=\"toc-item-num\">2.0.5&nbsp;&nbsp;</span>Dimensions - df.ndim</a></span></li><li><span><a href=\"#Size---df.size\" data-toc-modified-id=\"Size---df.size-2.0.6\"><span class=\"toc-item-num\">2.0.6&nbsp;&nbsp;</span>Size - df.size</a></span></li><li><span><a href=\"#Column-Names---df.columns\" data-toc-modified-id=\"Column-Names---df.columns-2.0.7\"><span class=\"toc-item-num\">2.0.7&nbsp;&nbsp;</span>Column Names - df.columns</a></span></li><li><span><a href=\"#Shape---df.shape\" data-toc-modified-id=\"Shape---df.shape-2.0.8\"><span class=\"toc-item-num\">2.0.8&nbsp;&nbsp;</span>Shape - df.shape</a></span></li><li><span><a href=\"#Head---Tail---df.<head,tail>(n)\" data-toc-modified-id=\"Head---Tail---df.<head,tail>(n)-2.0.9\"><span class=\"toc-item-num\">2.0.9&nbsp;&nbsp;</span>Head - Tail - df.&lt;head,tail&gt;(n)</a></span></li><li><span><a href=\"#Info---df.info()\" data-toc-modified-id=\"Info---df.info()-2.0.10\"><span class=\"toc-item-num\">2.0.10&nbsp;&nbsp;</span>Info - df.info()</a></span></li><li><span><a href=\"#Type---type(df)\" data-toc-modified-id=\"Type---type(df)-2.0.11\"><span class=\"toc-item-num\">2.0.11&nbsp;&nbsp;</span>Type - type(df)</a></span></li><li><span><a href=\"#Describe---df.describe(include=[<>,<>,<>])\" data-toc-modified-id=\"Describe---df.describe(include=[<>,<>,<>])-2.0.12\"><span class=\"toc-item-num\">2.0.12&nbsp;&nbsp;</span>Describe - df.describe(include=[&lt;&gt;,&lt;&gt;,&lt;&gt;])</a></span></li><li><span><a href=\"#Value_Counts---df.value_counts()\" data-toc-modified-id=\"Value_Counts---df.value_counts()-2.0.13\"><span class=\"toc-item-num\">2.0.13&nbsp;&nbsp;</span>Value_Counts - df.value_counts()</a></span></li><li><span><a href=\"#Correlation-Analysis---df.corr\" data-toc-modified-id=\"Correlation-Analysis---df.corr-2.0.14\"><span class=\"toc-item-num\">2.0.14&nbsp;&nbsp;</span>Correlation Analysis - df.corr</a></span></li></ul></li></ul></li><li><span><a href=\"#STAGE-2:-Data-Structuring\" data-toc-modified-id=\"STAGE-2:-Data-Structuring-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>STAGE 2: Data Structuring</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Rename-Columns---df.rename({})\" data-toc-modified-id=\"Rename-Columns---df.rename({})-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Rename Columns - df.rename({})</a></span></li><li><span><a href=\"#Rearrange-Columns---df[[]]\" data-toc-modified-id=\"Rearrange-Columns---df[[]]-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Rearrange Columns - df[[]]</a></span></li><li><span><a href=\"#Text-Data-Functions\" data-toc-modified-id=\"Text-Data-Functions-3.0.3\"><span class=\"toc-item-num\">3.0.3&nbsp;&nbsp;</span>Text Data Functions</a></span></li><li><span><a href=\"#Date-&amp;-Time\" data-toc-modified-id=\"Date-&amp;-Time-3.0.4\"><span class=\"toc-item-num\">3.0.4&nbsp;&nbsp;</span>Date &amp; Time</a></span></li></ul></li></ul></li><li><span><a href=\"#STAGE-3:-Data-Cleaning\" data-toc-modified-id=\"STAGE-3:-Data-Cleaning-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>STAGE 3: Data Cleaning</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Null-Values---df.isna().sum()\" data-toc-modified-id=\"Null-Values---df.isna().sum()-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Null Values - df.isna().sum()</a></span></li><li><span><a href=\"#Replace-Null-Values---fillna()------{parameters:-<&quot;NA&quot;,0>}\" data-toc-modified-id=\"Replace-Null-Values---fillna()------{parameters:-<&quot;NA&quot;,0>}-4.0.2\"><span class=\"toc-item-num\">4.0.2&nbsp;&nbsp;</span>Replace Null Values - fillna()      {parameters: &lt;\"NA\",0&gt;}</a></span></li><li><span><a href=\"#Eliminate-Null-Values---dropna()\" data-toc-modified-id=\"Eliminate-Null-Values---dropna()-4.0.3\"><span class=\"toc-item-num\">4.0.3&nbsp;&nbsp;</span>Eliminate Null Values - dropna()</a></span></li></ul></li></ul></li><li><span><a href=\"#STAGE-4:-Data-Enriching\" data-toc-modified-id=\"STAGE-4:-Data-Enriching-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>STAGE 4: Data Enriching</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Calculated-Columns\" data-toc-modified-id=\"Calculated-Columns-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span>Calculated Columns</a></span></li><li><span><a href=\"#Drop-Duplicate-Values---df.drop_duplicates()\" data-toc-modified-id=\"Drop-Duplicate-Values---df.drop_duplicates()-5.0.2\"><span class=\"toc-item-num\">5.0.2&nbsp;&nbsp;</span>Drop Duplicate Values - df.drop_duplicates()</a></span></li><li><span><a href=\"#Pivot-Tables---df.pivot_table()\" data-toc-modified-id=\"Pivot-Tables---df.pivot_table()-5.0.3\"><span class=\"toc-item-num\">5.0.3&nbsp;&nbsp;</span>Pivot Tables - df.pivot_table()</a></span></li><li><span><a href=\"#Freezepanes---df.set_index()\" data-toc-modified-id=\"Freezepanes---df.set_index()-5.0.4\"><span class=\"toc-item-num\">5.0.4&nbsp;&nbsp;</span>Freezepanes - df.set_index()</a></span></li><li><span><a href=\"#Selection-Columns-by-Label----df.loc()\" data-toc-modified-id=\"Selection-Columns-by-Label----df.loc()-5.0.5\"><span class=\"toc-item-num\">5.0.5&nbsp;&nbsp;</span>Selection Columns by Label  - df.loc()</a></span></li><li><span><a href=\"#Select-Specific-Columns\" data-toc-modified-id=\"Select-Specific-Columns-5.0.6\"><span class=\"toc-item-num\">5.0.6&nbsp;&nbsp;</span>Select Specific Columns</a></span></li><li><span><a href=\"#Selection-Columns-by-Position---df.iloc()\" data-toc-modified-id=\"Selection-Columns-by-Position---df.iloc()-5.0.7\"><span class=\"toc-item-num\">5.0.7&nbsp;&nbsp;</span>Selection Columns by Position - df.iloc()</a></span></li><li><span><a href=\"#Filter-Datasets\" data-toc-modified-id=\"Filter-Datasets-5.0.8\"><span class=\"toc-item-num\">5.0.8&nbsp;&nbsp;</span>Filter Datasets</a></span></li><li><span><a href=\"#Filter-Top-10-(Discrete-Objects)\" data-toc-modified-id=\"Filter-Top-10-(Discrete-Objects)-5.0.9\"><span class=\"toc-item-num\">5.0.9&nbsp;&nbsp;</span>Filter Top 10 (Discrete Objects)</a></span></li><li><span><a href=\"#Sort-Values---df.sort()\" data-toc-modified-id=\"Sort-Values---df.sort()-5.0.10\"><span class=\"toc-item-num\">5.0.10&nbsp;&nbsp;</span>Sort Values - df.sort()</a></span></li><li><span><a href=\"#Gruop-By---df[[]].groupby()\" data-toc-modified-id=\"Gruop-By---df[[]].groupby()-5.0.11\"><span class=\"toc-item-num\">5.0.11&nbsp;&nbsp;</span>Gruop By - df[[]].groupby()</a></span></li><li><span><a href=\"#If---Elif---Else\" data-toc-modified-id=\"If---Elif---Else-5.0.12\"><span class=\"toc-item-num\">5.0.12&nbsp;&nbsp;</span>If - Elif - Else</a></span></li><li><span><a href=\"#Bucles-For\" data-toc-modified-id=\"Bucles-For-5.0.13\"><span class=\"toc-item-num\">5.0.13&nbsp;&nbsp;</span>Bucles For</a></span></li><li><span><a href=\"#Lists-[-]\" data-toc-modified-id=\"Lists-[-]-5.0.14\"><span class=\"toc-item-num\">5.0.14&nbsp;&nbsp;</span>Lists [ ]</a></span></li><li><span><a href=\"#Tuples-(-)\" data-toc-modified-id=\"Tuples-(-)-5.0.15\"><span class=\"toc-item-num\">5.0.15&nbsp;&nbsp;</span>Tuples ( )</a></span></li><li><span><a href=\"#Dictionaries-{-}\" data-toc-modified-id=\"Dictionaries-{-}-5.0.16\"><span class=\"toc-item-num\">5.0.16&nbsp;&nbsp;</span>Dictionaries { }</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-5.0.17\"><span class=\"toc-item-num\">5.0.17&nbsp;&nbsp;</span>Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Functions-with-No-Arguments\" data-toc-modified-id=\"Functions-with-No-Arguments-5.0.17.1\"><span class=\"toc-item-num\">5.0.17.1&nbsp;&nbsp;</span>Functions with No Arguments</a></span></li><li><span><a href=\"#Functions-with-One-Single-Argument\" data-toc-modified-id=\"Functions-with-One-Single-Argument-5.0.17.2\"><span class=\"toc-item-num\">5.0.17.2&nbsp;&nbsp;</span>Functions with One-Single Argument</a></span></li><li><span><a href=\"#Functions-with-Multiple-Arguments.\" data-toc-modified-id=\"Functions-with-Multiple-Arguments.-5.0.17.3\"><span class=\"toc-item-num\">5.0.17.3&nbsp;&nbsp;</span>Functions with Multiple Arguments.</a></span></li></ul></li><li><span><a href=\"#Loops\" data-toc-modified-id=\"Loops-5.0.18\"><span class=\"toc-item-num\">5.0.18&nbsp;&nbsp;</span>Loops</a></span></li><li><span><a href=\"#Append---df.append()\" data-toc-modified-id=\"Append---df.append()-5.0.19\"><span class=\"toc-item-num\">5.0.19&nbsp;&nbsp;</span>Append - df.append()</a></span></li><li><span><a href=\"#Concatenate----pd.concatenate()\" data-toc-modified-id=\"Concatenate----pd.concatenate()-5.0.20\"><span class=\"toc-item-num\">5.0.20&nbsp;&nbsp;</span>Concatenate  - pd.concatenate()</a></span></li><li><span><a href=\"#Joins\" data-toc-modified-id=\"Joins-5.0.21\"><span class=\"toc-item-num\">5.0.21&nbsp;&nbsp;</span>Joins</a></span></li><li><span><a href=\"#Subsets\" data-toc-modified-id=\"Subsets-5.0.22\"><span class=\"toc-item-num\">5.0.22&nbsp;&nbsp;</span>Subsets</a></span></li><li><span><a href=\"#Convert-List-into-Arrays-(with-Numpy)\" data-toc-modified-id=\"Convert-List-into-Arrays-(with-Numpy)-5.0.23\"><span class=\"toc-item-num\">5.0.23&nbsp;&nbsp;</span>Convert List into Arrays (with Numpy)</a></span></li><li><span><a href=\"#Stack-Arrays\" data-toc-modified-id=\"Stack-Arrays-5.0.24\"><span class=\"toc-item-num\">5.0.24&nbsp;&nbsp;</span>Stack Arrays</a></span></li><li><span><a href=\"#Summarize-Figures\" data-toc-modified-id=\"Summarize-Figures-5.0.25\"><span class=\"toc-item-num\">5.0.25&nbsp;&nbsp;</span>Summarize Figures</a></span></li><li><span><a href=\"#Arrays-(Vectors)-with-Numpy\" data-toc-modified-id=\"Arrays-(Vectors)-with-Numpy-5.0.26\"><span class=\"toc-item-num\">5.0.26&nbsp;&nbsp;</span>Arrays (Vectors) with Numpy</a></span></li></ul></li></ul></li><li><span><a href=\"#STAGE-5:-Data-Publishing\" data-toc-modified-id=\"STAGE-5:-Data-Publishing-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>STAGE 5: Data Publishing</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Writing-Files\" data-toc-modified-id=\"Writing-Files-6.0.1\"><span class=\"toc-item-num\">6.0.1&nbsp;&nbsp;</span>Writing Files</a></span></li><li><span><a href=\"#Pushing-Jupyter-Notebooks-in-Github/Gitlab\" data-toc-modified-id=\"Pushing-Jupyter-Notebooks-in-Github/Gitlab-6.0.2\"><span class=\"toc-item-num\">6.0.2&nbsp;&nbsp;</span>Pushing Jupyter Notebooks in Github/Gitlab</a></span></li></ul></li></ul></li><li><span><a href=\"#Annexes:\" data-toc-modified-id=\"Annexes:-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Annexes:</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#01.-Data-Wrangling-Best-Practices\" data-toc-modified-id=\"01.-Data-Wrangling-Best-Practices-7.0.1\"><span class=\"toc-item-num\">7.0.1&nbsp;&nbsp;</span>01. Data Wrangling Best Practices</a></span></li><li><span><a href=\"#Help-Function---help()\" data-toc-modified-id=\"Help-Function---help()-7.0.2\"><span class=\"toc-item-num\">7.0.2&nbsp;&nbsp;</span>Help Function - help()</a></span></li><li><span><a href=\"#Print-Function---print('-')\" data-toc-modified-id=\"Print-Function---print('-')-7.0.3\"><span class=\"toc-item-num\">7.0.3&nbsp;&nbsp;</span>Print Function - print(' ')</a></span></li><li><span><a href=\"#Type()\" data-toc-modified-id=\"Type()-7.0.4\"><span class=\"toc-item-num\">7.0.4&nbsp;&nbsp;</span>Type()</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722d1b5",
   "metadata": {},
   "source": [
    "# DATA WRANGLING\n",
    "Data Wrangling is the process of cleaning, organizing, structuring, and enriching the raw data to make it more useful for analysis and visualization purposes. With more unstructured data, it is essential to perform Data Wrangling for making smarter and more accurate business decisions. Data Wrangling usually involves manually converting and mapping data from its raw state to another format that can be used for business purposes and is convenient for the consumption and organization of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a49544",
   "metadata": {},
   "source": [
    "Data Wrangling Stages:\n",
    "\n",
    "* Step 1: Data Discovery\n",
    "* Step 2: Data Structuring\n",
    "* Step 3: Data Cleaning\n",
    "* Step 4: Data Enriching\n",
    "* Step 5: Data Validating\n",
    "* Step 6: Data Publishing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4714447",
   "metadata": {},
   "source": [
    "# STAGE 1: Data Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bffe78b",
   "metadata": {},
   "source": [
    "The first step in the Data Wrangling process is Discovery. This is an all-encompassing term for understanding or getting familiar with your data. You must take a look at the data you have and think about how you would like it organized to make it easier to consume and analyze. \n",
    "\n",
    "So, you begin with an Unruly Crowd of Data collected from multiple sources in a wide range of formats. At this stage, the goal is to compile the Disparate, Siloed data sources and configure each of them so they can be understood and examined to find patterns and trends in the data.\n",
    "\n",
    "https://hevodata.com/learn/data-wrangling/#s1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0707eb6d",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab8b0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 1.4.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print('pandas', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40224f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BooleanDtype', 'Categorical', 'CategoricalDtype', 'CategoricalIndex', 'DataFrame', 'DateOffset', 'DatetimeIndex', 'DatetimeTZDtype', 'ExcelFile', 'ExcelWriter', 'Flags', 'Float32Dtype', 'Float64Dtype', 'Float64Index', 'Grouper', 'HDFStore', 'Index', 'IndexSlice', 'Int16Dtype', 'Int32Dtype', 'Int64Dtype', 'Int64Index', 'Int8Dtype', 'Interval', 'IntervalDtype', 'IntervalIndex', 'MultiIndex', 'NA', 'NaT', 'NamedAgg', 'Period', 'PeriodDtype', 'PeriodIndex', 'RangeIndex', 'Series', 'SparseDtype', 'StringDtype', 'Timedelta', 'TimedeltaIndex', 'Timestamp', 'UInt16Dtype', 'UInt32Dtype', 'UInt64Dtype', 'UInt64Index', 'UInt8Dtype', '__all__', '__builtins__', '__cached__', '__deprecated_num_index_names', '__dir__', '__doc__', '__docformat__', '__file__', '__getattr__', '__git_version__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_config', '_is_numpy_dev', '_libs', '_testing', '_typing', '_version', 'api', 'array', 'arrays', 'bdate_range', 'compat', 'concat', 'core', 'crosstab', 'cut', 'date_range', 'describe_option', 'errors', 'eval', 'factorize', 'get_dummies', 'get_option', 'infer_freq', 'interval_range', 'io', 'isna', 'isnull', 'json_normalize', 'lreshape', 'melt', 'merge', 'merge_asof', 'merge_ordered', 'notna', 'notnull', 'offsets', 'option_context', 'options', 'pandas', 'period_range', 'pivot', 'pivot_table', 'plotting', 'qcut', 'read_clipboard', 'read_csv', 'read_excel', 'read_feather', 'read_fwf', 'read_gbq', 'read_hdf', 'read_html', 'read_json', 'read_orc', 'read_parquet', 'read_pickle', 'read_sas', 'read_spss', 'read_sql', 'read_sql_query', 'read_sql_table', 'read_stata', 'read_table', 'read_xml', 'reset_option', 'set_eng_float_format', 'set_option', 'show_versions', 'test', 'testing', 'timedelta_range', 'to_datetime', 'to_numeric', 'to_pickle', 'to_timedelta', 'tseries', 'unique', 'util', 'value_counts', 'wide_to_long']\n"
     ]
    }
   ],
   "source": [
    "# Additional libraries functions:\n",
    "# Consult library functions \n",
    "print(dir(pd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18863c2",
   "metadata": {},
   "source": [
    "### Define a Work Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0e747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_path = os.path.abspath(\n",
    "    'C:\\\\Users\\\\Asus VivoBook\\\\Dropbox\\\\My PC (DESKTOP-GN5CQHE)\\\\Desktop\\\\Documentos\\\\The Vault\\\\Python\\\\PyWD'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e2e7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the WD exists\n",
    "if not os.path.exists(wd_path):\n",
    "    # create the directory if it doesn't exist\n",
    "    os.makedirs(wd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c061c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Asus VivoBook\\\\AnthonyCRENG28\\\\Definitive_Guide'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the WD\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb790ac",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Modifying the WD path\n",
    "####### The following instruction modifies the Working Directory path:\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\DELL\\\\Documents\\\\\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81068537",
   "metadata": {},
   "source": [
    "### Reading Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01d3312",
   "metadata": {},
   "source": [
    "#### Read CSV files\n",
    "pd.read_csv is a function in the panda's library in Python that is used to read a CSV(Comma Separated Values) file and convert it into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a725a1",
   "metadata": {},
   "source": [
    "###### Method_01: With Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459a146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus VivoBook\\AppData\\Local\\Temp\\ipykernel_17268\\216861829.py:2: DtypeWarning: Columns (5,21,22,23,24,34,36,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_csv = pd.read_csv('C:\\\\Users\\\\Asus VivoBook\\\\Dropbox\\\\My PC (DESKTOP-GN5CQHE)\\\\Desktop\\\\Documentos\\\\The Vault\\\\Python\\\\PyWD\\\\Global Pollution.csv')\n"
     ]
    }
   ],
   "source": [
    "df_csv = pd.read_csv('C:\\\\Users\\\\Asus VivoBook\\\\Dropbox\\\\My PC (DESKTOP-GN5CQHE)\\\\Desktop\\\\Documentos\\\\The Vault\\\\Python\\\\PyWD\\\\Global Pollution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81049db9",
   "metadata": {},
   "source": [
    "###### Method_02: Without Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"E:/MLDataSets/emp10.csv\") as a:\n",
    " d = csv.DictReader(a)\n",
    " l=list(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4bfec1",
   "metadata": {},
   "source": [
    "#### Read CSV File from External URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"http://winterolympicsmedals.com/medals.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2362a593",
   "metadata": {},
   "source": [
    "#### Read_CSV: Addtitional Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2422389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Measure time taken to import big CSV file\n",
    "With the use of verbose=True, you can capture time taken for\n",
    "Tokenization, conversion and Parser memory cleanup.\n",
    "emp = pd.read_csv(\"emp10.csv\", verbose=True)\n",
    "\n",
    "###### Define your own column names instead of header row from CSV file\n",
    "emp1 = pd.read_csv(\"emp10.csv\", skiprows=1,\n",
    "names=['Emp_ID','Emp_Name','Emp_Desig','Emp_DOJ','Emp_\n",
    "Sal'])\n",
    "print(emp1)\n",
    "skiprows = 1 means we are ignoring first row and names=\n",
    "option is used to assign variable names manually.\n",
    "\n",
    "###### Add prefix to column names\n",
    "emp1 = pd.read_csv(\"emp10.csv\", header = None,\n",
    "prefix=\"var\")\n",
    "print(emp1)\n",
    "In this case, we are setting var as prefix which tells python to\n",
    "include this keyword before each column name.\n",
    "\n",
    "###### Specify missing values\n",
    "The na_values= options is used to set some values as blank /\n",
    "missing values while importing CSV file.\n",
    "emp1 = pd.read_csv(\"emp10.csv\", na_values=['.'])\n",
    "print(emp1)\n",
    "\n",
    "###### Change column type while importing CSV\n",
    "Suppose you want to change column format from int64 to\n",
    "float64 while loading CSV file into Python. We can use dtype =\n",
    "option for the same.\n",
    "emp = pd.read_csv(\"emp10.csv\", dtype = {\"sal\" : \"float64\"})\n",
    "print(emp)\n",
    "emp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c6db36",
   "metadata": {},
   "source": [
    "#### Read XLSX files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313fb348",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Asus VivoBook\\Dropbox\\My PC (DESKTOP-GN5CQHE)\\Documents\\My Studies\\PowerUp Institute\\Python\\week 01'\n",
    "df = pd.ExcelFile(path+'\\AdventureWorks.Xlsx').parse(sheet_name='Customer',header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc91ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Alternative method:\n",
    "###### The read_excel() function can be used to import excel data into Python.\n",
    "###### If you do not specify name of sheet in sheetname= option, it would take by default first sheet.\n",
    "    \n",
    "emp = pd.read_excel(\"E:/MLDataSets/emp10.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1e146",
   "metadata": {},
   "source": [
    "#### Read TXT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### We can use read_table() function to pull data from text file. \n",
    "####### We can also use read_csv() with sep= \"\\t\" to read data from tabseparated file.\n",
    "a = pd.read_table(\"E:/MLDataSets/demo.txt\")\n",
    "a = pd.read_csv(\"E:/MLDataSets/demo.csv\", sep =\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58711d2f",
   "metadata": {},
   "source": [
    "#### Read Delimited files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Suppose you need to import a file that is separated with whitespaces.\n",
    "mydata2 = pd.read_table(\"http://www.ssc.wisc.edu/~bhansen/econometrics/invest.dat\", sep=\"\\s+\", header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f73d9f6",
   "metadata": {},
   "source": [
    "#### Read JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Load the JSON file into a Pandas dataframe\n",
    "df = pd.read_json('C:\\data\\export.json')\n",
    "\n",
    "###### Write the dataframe to a CSV file\n",
    "df.to_csv(r'C:\\data\\export.csv', index=False)\n",
    "\n",
    "###### Alternatively, you can use the os library to open the csv automatically.\n",
    "import os\n",
    "os.startfile('C:\\data\\export.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca9b7d6",
   "metadata": {},
   "source": [
    "#### Read ORC files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc72ed5",
   "metadata": {},
   "source": [
    "###### Method_01: pandas + pyarrow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Read ORC files, then convert to csv format\n",
    "# Open the ORC file\n",
    "file = orc.ORCFile(filename)\n",
    "# Read the entire ORC file into a table\n",
    "table = file.read()\n",
    "# Convert the table to a pandas DataFrame\n",
    "df = table.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f54c4",
   "metadata": {},
   "source": [
    "###### Method_02: pandas + pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b75ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.orc as orc\n",
    "\n",
    "with open(filename) as file:\n",
    "    data = orc.ORCFile(file)\n",
    "    df = data.read().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01bfe1",
   "metadata": {},
   "source": [
    "#### Read AVRO files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2937a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Read AVRO files, then convert to csv format\n",
    "\n",
    "# Open the Avro file\n",
    "with open('file.avro', 'rb') as f:\n",
    "    reader = fastavro.reader(f)\n",
    "# Iterate over the records in the Avro file\n",
    "    for record in reader:\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964ce49",
   "metadata": {},
   "source": [
    "#### Read ZIP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ff4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read ZIP files, then convert to csv format\n",
    "# Read the zip file\n",
    "with zipfile.ZipFile('C:\\data\\jar_files.zip', \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"extracted_content\")\n",
    "\n",
    "# read the extracted file into a pandas dataframe\n",
    "df = pd.read_csv('extracted_content\\C:\\data\\export.csv')\n",
    "\n",
    "# save the dataframe as a csv file\n",
    "df.to_csv(\"converted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf034ab4",
   "metadata": {},
   "source": [
    "### Dimensions - df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6770c03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cac9e3",
   "metadata": {},
   "source": [
    "### Size - df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b34c1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4514204"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327db72",
   "metadata": {},
   "source": [
    "### Column Names - df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "611ceeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'OBJECTID', 'RecordSequenceID', 'UniqueID', 'SourceID',\n",
       "       'LocationFreqID', 'Location', 'Dataset', 'Organization', 'Other',\n",
       "       'CountryName_FromSource', 'SubCountry_L1_FromSource',\n",
       "       'SubCountry_L2_FromSource', 'Longitude1', 'Latitude1', 'Longitude2',\n",
       "       'Latitude2', 'TotalWidth_m', 'TotalLength_m', 'TotalArea_Sq_m',\n",
       "       'ShorelineName', 'WaterfrontName', 'BeachAreaLandcover', 'BeachType',\n",
       "       'EventType', 'TotalVolunteers', 'DateOriginal', 'DateStandardized',\n",
       "       'MonthYear', 'Year', 'MonthNum', 'Month', 'Day', 'StartTime', 'DOW',\n",
       "       'FieldObsevations', 'DebrisDescription', 'Totalltems_EventRecord',\n",
       "       'TotalClassifiedItems_EC2020', 'PCT_PlasticAndFoam',\n",
       "       'PCT_Glass_Rubber_Lumber_Metal', 'SUM_Hard_PlasticBeverageBottle',\n",
       "       'SUM_Hard_OtherPlasticBottle', 'SUM_HardOrSoft_PlasticBottleCap',\n",
       "       'SUM_PlasticOrFoamFoodContainer', 'SUM_Hard_BucketOrCrate',\n",
       "       'SUM_Hard_Lighter', 'SUM_OtherHardPlastic',\n",
       "       'SUM_PlasticOrFoamPlatesBowlsCup', 'SUM_HardSoft_PersonalCareProduc',\n",
       "       'SUM_HardSoftLollipopStick_EarBu', 'SUM_Soft_Bag',\n",
       "       'SUM_Soft_WrapperOrLabel', 'SUM_Soft_Straw', 'SUM_Soft_OtherPlastic',\n",
       "       'SUM_Soft_CigaretteButts', 'SUM_Soft_StringRingRibbon', 'Fishing_Net',\n",
       "       'SUM_FishingLineLureRope', 'Fishing_BuoysAndFloats',\n",
       "       'SUM_Foam_OtherPlasticDebris', 'SUM_OtherPlasticDebris', 'NAME',\n",
       "       'COUNTRY', 'ISO_CODE', 'ISO_CC', 'ISO_SUB', 'ADMINTYPE', 'DISPUTED',\n",
       "       'NOTES', 'AUTONOMOUS', 'COUNTRYAFF', 'CONTINENT', 'LAND_TYPE',\n",
       "       'LAND_RANK', 'Shape__Area', 'Shape__Length', 'Count_', 'Soft_Sheets2',\n",
       "       'PlasticStraps2', 'FishingGlowSticks2', 'FishingOtherPlasticDebris2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fe1ad",
   "metadata": {},
   "source": [
    "### Shape - df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a074029d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54388, 83)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae70a582",
   "metadata": {},
   "source": [
    "### Head - Tail - df.<head,tail>(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42767e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>RecordSequenceID</th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>LocationFreqID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Organization</th>\n",
       "      <th>...</th>\n",
       "      <th>CONTINENT</th>\n",
       "      <th>LAND_TYPE</th>\n",
       "      <th>LAND_RANK</th>\n",
       "      <th>Shape__Area</th>\n",
       "      <th>Shape__Length</th>\n",
       "      <th>Count_</th>\n",
       "      <th>Soft_Sheets2</th>\n",
       "      <th>PlasticStraps2</th>\n",
       "      <th>FishingGlowSticks2</th>\n",
       "      <th>FishingOtherPlasticDebris2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-123.435585</td>\n",
       "      <td>38.690549</td>\n",
       "      <td>1</td>\n",
       "      <td>349</td>\n",
       "      <td>MDP-349</td>\n",
       "      <td>40-3153</td>\n",
       "      <td>Blackpoint Beach (Lon -123.4355847 Lat 38.6905...</td>\n",
       "      <td>Blackpoint Beach, Sonoma, CA, United States</td>\n",
       "      <td>NOAA MDMAP Accumulation Survey</td>\n",
       "      <td>California Coast National Monument Task Force</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Primary land</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.506355</td>\n",
       "      <td>56.81446</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-123.484406</td>\n",
       "      <td>38.728707</td>\n",
       "      <td>2</td>\n",
       "      <td>351</td>\n",
       "      <td>MDP-351</td>\n",
       "      <td>37-3164</td>\n",
       "      <td>Dune Drift Beach (Lon -123.4844062 Lat 38.7287...</td>\n",
       "      <td>Dune Drift Beach, Sonoma, CA, United States</td>\n",
       "      <td>NOAA MDMAP Accumulation Survey</td>\n",
       "      <td>California Coast National Monument Task Force</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Primary land</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.506355</td>\n",
       "      <td>56.81446</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-123.456400</td>\n",
       "      <td>38.713200</td>\n",
       "      <td>3</td>\n",
       "      <td>354</td>\n",
       "      <td>MDP-354</td>\n",
       "      <td>59-3175</td>\n",
       "      <td>Ohlson Beach (Lon -123.4564 Lat 38.7132)</td>\n",
       "      <td>Ohlson Beach, Sonoma, CA, United States</td>\n",
       "      <td>NOAA MDMAP Accumulation Survey</td>\n",
       "      <td>California Coast National Monument Task Force</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Primary land</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.506355</td>\n",
       "      <td>56.81446</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X          Y  OBJECTID  RecordSequenceID UniqueID SourceID  \\\n",
       "0 -123.435585  38.690549         1               349  MDP-349  40-3153   \n",
       "1 -123.484406  38.728707         2               351  MDP-351  37-3164   \n",
       "2 -123.456400  38.713200         3               354  MDP-354  59-3175   \n",
       "\n",
       "                                      LocationFreqID  \\\n",
       "0  Blackpoint Beach (Lon -123.4355847 Lat 38.6905...   \n",
       "1  Dune Drift Beach (Lon -123.4844062 Lat 38.7287...   \n",
       "2           Ohlson Beach (Lon -123.4564 Lat 38.7132)   \n",
       "\n",
       "                                      Location  \\\n",
       "0  Blackpoint Beach, Sonoma, CA, United States   \n",
       "1  Dune Drift Beach, Sonoma, CA, United States   \n",
       "2      Ohlson Beach, Sonoma, CA, United States   \n",
       "\n",
       "                          Dataset  \\\n",
       "0  NOAA MDMAP Accumulation Survey   \n",
       "1  NOAA MDMAP Accumulation Survey   \n",
       "2  NOAA MDMAP Accumulation Survey   \n",
       "\n",
       "                                    Organization  ...      CONTINENT  \\\n",
       "0  California Coast National Monument Task Force  ...  North America   \n",
       "1  California Coast National Monument Task Force  ...  North America   \n",
       "2  California Coast National Monument Task Force  ...  North America   \n",
       "\n",
       "      LAND_TYPE LAND_RANK Shape__Area  Shape__Length  Count_  Soft_Sheets2  \\\n",
       "0  Primary land       5.0   41.506355       56.81446       1             0   \n",
       "1  Primary land       5.0   41.506355       56.81446       1             0   \n",
       "2  Primary land       5.0   41.506355       56.81446       1             0   \n",
       "\n",
       "   PlasticStraps2  FishingGlowSticks2  FishingOtherPlasticDebris2  \n",
       "0               0                   0                           0  \n",
       "1               0                   0                           0  \n",
       "2               0                   0                           0  \n",
       "\n",
       "[3 rows x 83 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af3dadd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>RecordSequenceID</th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>LocationFreqID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Organization</th>\n",
       "      <th>...</th>\n",
       "      <th>CONTINENT</th>\n",
       "      <th>LAND_TYPE</th>\n",
       "      <th>LAND_RANK</th>\n",
       "      <th>Shape__Area</th>\n",
       "      <th>Shape__Length</th>\n",
       "      <th>Count_</th>\n",
       "      <th>Soft_Sheets2</th>\n",
       "      <th>PlasticStraps2</th>\n",
       "      <th>FishingGlowSticks2</th>\n",
       "      <th>FishingOtherPlasticDebris2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54385</th>\n",
       "      <td>-124.14953</td>\n",
       "      <td>40.86556</td>\n",
       "      <td>54878</td>\n",
       "      <td>61767</td>\n",
       "      <td>TID-56241</td>\n",
       "      <td>109779</td>\n",
       "      <td>TIDES (Lon -124.14953098159 Lat 40.865556085634)</td>\n",
       "      <td>Humboldt County, CA, USA</td>\n",
       "      <td>Oecan Conservancy TIDES Report</td>\n",
       "      <td>NEC CCD 2015</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Primary land</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.506355</td>\n",
       "      <td>56.81446</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54386</th>\n",
       "      <td>-124.12611</td>\n",
       "      <td>40.95918</td>\n",
       "      <td>54879</td>\n",
       "      <td>61768</td>\n",
       "      <td>TID-56242</td>\n",
       "      <td>109808</td>\n",
       "      <td>TIDES (Lon -124.12610524606 Lat 40.959183318067)</td>\n",
       "      <td>Humboldt County, CA, USA</td>\n",
       "      <td>Oecan Conservancy TIDES Report</td>\n",
       "      <td>NEC CCD 2015</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Primary land</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.506355</td>\n",
       "      <td>56.81446</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54387</th>\n",
       "      <td>-124.13212</td>\n",
       "      <td>40.93425</td>\n",
       "      <td>54880</td>\n",
       "      <td>61769</td>\n",
       "      <td>TID-56243</td>\n",
       "      <td>109809</td>\n",
       "      <td>TIDES (Lon -124.13212255857 Lat 40.93424666982)</td>\n",
       "      <td>Humboldt County, CA, USA</td>\n",
       "      <td>Oecan Conservancy TIDES Report</td>\n",
       "      <td>NEC CCD 2015</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Primary land</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.506355</td>\n",
       "      <td>56.81446</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X         Y  OBJECTID  RecordSequenceID   UniqueID SourceID  \\\n",
       "54385 -124.14953  40.86556     54878             61767  TID-56241   109779   \n",
       "54386 -124.12611  40.95918     54879             61768  TID-56242   109808   \n",
       "54387 -124.13212  40.93425     54880             61769  TID-56243   109809   \n",
       "\n",
       "                                         LocationFreqID  \\\n",
       "54385  TIDES (Lon -124.14953098159 Lat 40.865556085634)   \n",
       "54386  TIDES (Lon -124.12610524606 Lat 40.959183318067)   \n",
       "54387   TIDES (Lon -124.13212255857 Lat 40.93424666982)   \n",
       "\n",
       "                       Location                         Dataset  Organization  \\\n",
       "54385  Humboldt County, CA, USA  Oecan Conservancy TIDES Report  NEC CCD 2015   \n",
       "54386  Humboldt County, CA, USA  Oecan Conservancy TIDES Report  NEC CCD 2015   \n",
       "54387  Humboldt County, CA, USA  Oecan Conservancy TIDES Report  NEC CCD 2015   \n",
       "\n",
       "       ...      CONTINENT     LAND_TYPE LAND_RANK Shape__Area  Shape__Length  \\\n",
       "54385  ...  North America  Primary land       5.0   41.506355       56.81446   \n",
       "54386  ...  North America  Primary land       5.0   41.506355       56.81446   \n",
       "54387  ...  North America  Primary land       5.0   41.506355       56.81446   \n",
       "\n",
       "       Count_  Soft_Sheets2  PlasticStraps2  FishingGlowSticks2  \\\n",
       "54385       1             0               0                   0   \n",
       "54386       1             0               0                   0   \n",
       "54387       1             0               1                   0   \n",
       "\n",
       "       FishingOtherPlasticDebris2  \n",
       "54385                           0  \n",
       "54386                           0  \n",
       "54387                           0  \n",
       "\n",
       "[3 rows x 83 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a73d043",
   "metadata": {},
   "source": [
    "### Info - df.info()\n",
    "Is a method in pandas that is used to get a concise summary of theDataFrame, including the number of non-null values in each column, the data types ofeach column, and the memory usage of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "040ec7e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54388 entries, 0 to 54387\n",
      "Data columns (total 83 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   X                                54388 non-null  float64\n",
      " 1   Y                                54388 non-null  float64\n",
      " 2   OBJECTID                         54388 non-null  int64  \n",
      " 3   RecordSequenceID                 54388 non-null  int64  \n",
      " 4   UniqueID                         54388 non-null  object \n",
      " 5   SourceID                         51970 non-null  object \n",
      " 6   LocationFreqID                   54388 non-null  object \n",
      " 7   Location                         51142 non-null  object \n",
      " 8   Dataset                          54388 non-null  object \n",
      " 9   Organization                     43588 non-null  object \n",
      " 10  Other                            0 non-null      float64\n",
      " 11  CountryName_FromSource           50412 non-null  object \n",
      " 12  SubCountry_L1_FromSource         48291 non-null  object \n",
      " 13  SubCountry_L2_FromSource         48724 non-null  object \n",
      " 14  Longitude1                       54388 non-null  float64\n",
      " 15  Latitude1                        54388 non-null  float64\n",
      " 16  Longitude2                       4539 non-null   float64\n",
      " 17  Latitude2                        4539 non-null   float64\n",
      " 18  TotalWidth_m                     2121 non-null   float64\n",
      " 19  TotalLength_m                    54388 non-null  float64\n",
      " 20  TotalArea_Sq_m                   0 non-null      float64\n",
      " 21  ShorelineName                    4539 non-null   object \n",
      " 22  WaterfrontName                   1306 non-null   object \n",
      " 23  BeachAreaLandcover               1110 non-null   object \n",
      " 24  BeachType                        1114 non-null   object \n",
      " 25  EventType                        54388 non-null  object \n",
      " 26  TotalVolunteers                  51970 non-null  float64\n",
      " 27  DateOriginal                     51970 non-null  object \n",
      " 28  DateStandardized                 54388 non-null  object \n",
      " 29  MonthYear                        54388 non-null  object \n",
      " 30  Year                             54388 non-null  int64  \n",
      " 31  MonthNum                         54388 non-null  int64  \n",
      " 32  Month                            54388 non-null  object \n",
      " 33  Day                              54388 non-null  int64  \n",
      " 34  StartTime                        2121 non-null   object \n",
      " 35  DOW                              54388 non-null  object \n",
      " 36  FieldObsevations                 1064 non-null   object \n",
      " 37  DebrisDescription                1123 non-null   object \n",
      " 38  Totalltems_EventRecord           54388 non-null  int64  \n",
      " 39  TotalClassifiedItems_EC2020      54388 non-null  int64  \n",
      " 40  PCT_PlasticAndFoam               54388 non-null  float64\n",
      " 41  PCT_Glass_Rubber_Lumber_Metal    54388 non-null  float64\n",
      " 42  SUM_Hard_PlasticBeverageBottle   54388 non-null  int64  \n",
      " 43  SUM_Hard_OtherPlasticBottle      54388 non-null  int64  \n",
      " 44  SUM_HardOrSoft_PlasticBottleCap  54388 non-null  int64  \n",
      " 45  SUM_PlasticOrFoamFoodContainer   53580 non-null  float64\n",
      " 46  SUM_Hard_BucketOrCrate           54388 non-null  int64  \n",
      " 47  SUM_Hard_Lighter                 53302 non-null  float64\n",
      " 48  SUM_OtherHardPlastic             54388 non-null  int64  \n",
      " 49  SUM_PlasticOrFoamPlatesBowlsCup  54388 non-null  int64  \n",
      " 50  SUM_HardSoft_PersonalCareProduc  54388 non-null  int64  \n",
      " 51  SUM_HardSoftLollipopStick_EarBu  54388 non-null  int64  \n",
      " 52  SUM_Soft_Bag                     54388 non-null  int64  \n",
      " 53  SUM_Soft_WrapperOrLabel          54388 non-null  int64  \n",
      " 54  SUM_Soft_Straw                   53489 non-null  float64\n",
      " 55  SUM_Soft_OtherPlastic            54388 non-null  int64  \n",
      " 56  SUM_Soft_CigaretteButts          53849 non-null  float64\n",
      " 57  SUM_Soft_StringRingRibbon        54388 non-null  int64  \n",
      " 58  Fishing_Net                      54388 non-null  int64  \n",
      " 59  SUM_FishingLineLureRope          54388 non-null  int64  \n",
      " 60  Fishing_BuoysAndFloats           54388 non-null  int64  \n",
      " 61  SUM_Foam_OtherPlasticDebris      54388 non-null  int64  \n",
      " 62  SUM_OtherPlasticDebris           51970 non-null  float64\n",
      " 63  NAME                             53716 non-null  object \n",
      " 64  COUNTRY                          53716 non-null  object \n",
      " 65  ISO_CODE                         53716 non-null  object \n",
      " 66  ISO_CC                           53715 non-null  object \n",
      " 67  ISO_SUB                          53705 non-null  object \n",
      " 68  ADMINTYPE                        53716 non-null  object \n",
      " 69  DISPUTED                         53716 non-null  float64\n",
      " 70  NOTES                            49498 non-null  object \n",
      " 71  AUTONOMOUS                       53716 non-null  float64\n",
      " 72  COUNTRYAFF                       53716 non-null  object \n",
      " 73  CONTINENT                        53716 non-null  object \n",
      " 74  LAND_TYPE                        53716 non-null  object \n",
      " 75  LAND_RANK                        53716 non-null  float64\n",
      " 76  Shape__Area                      53716 non-null  float64\n",
      " 77  Shape__Length                    53716 non-null  float64\n",
      " 78  Count_                           54388 non-null  int64  \n",
      " 79  Soft_Sheets2                     54388 non-null  int64  \n",
      " 80  PlasticStraps2                   54388 non-null  int64  \n",
      " 81  FishingGlowSticks2               54388 non-null  int64  \n",
      " 82  FishingOtherPlasticDebris2       54388 non-null  int64  \n",
      "dtypes: float64(23), int64(28), object(32)\n",
      "memory usage: 34.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc44f6a",
   "metadata": {},
   "source": [
    "### Type - type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aadfb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007de04",
   "metadata": {},
   "source": [
    "### Describe - df.describe(include=[<>,<>,<>]) \n",
    "\n",
    "####### Descriptive Statistics\n",
    "\n",
    "####### Descriptive statistics are brief informational coefficients that summarize a given data set, which can be either a representation of the entire population or a sample of a population. Descriptive statistics are broken down into measures of central tendency and measures of variability (spread). \n",
    "\n",
    "####### Measures of Central tendency: the mean, median, and mode\n",
    "####### Measures of Variability: standard deviation, variance, minimum and maximum variables, kurtosis, and skewness.\n",
    "\n",
    "####### https://www.investopedia.com/terms/d/descriptive_statistics.asp\n",
    "\n",
    "####### Example:\n",
    "df.describe(include={'x','x','x']) \n",
    "where x = Parameters: <object, bool, all>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23a6783b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>LocationFreqID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Organization</th>\n",
       "      <th>CountryName_FromSource</th>\n",
       "      <th>SubCountry_L1_FromSource</th>\n",
       "      <th>SubCountry_L2_FromSource</th>\n",
       "      <th>ShorelineName</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>ISO_CODE</th>\n",
       "      <th>ISO_CC</th>\n",
       "      <th>ISO_SUB</th>\n",
       "      <th>ADMINTYPE</th>\n",
       "      <th>NOTES</th>\n",
       "      <th>COUNTRYAFF</th>\n",
       "      <th>CONTINENT</th>\n",
       "      <th>LAND_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54388</td>\n",
       "      <td>51970</td>\n",
       "      <td>54388</td>\n",
       "      <td>51142</td>\n",
       "      <td>54388</td>\n",
       "      <td>43588</td>\n",
       "      <td>50412</td>\n",
       "      <td>48291</td>\n",
       "      <td>48724</td>\n",
       "      <td>4539</td>\n",
       "      <td>...</td>\n",
       "      <td>53716</td>\n",
       "      <td>53716</td>\n",
       "      <td>53716</td>\n",
       "      <td>53715</td>\n",
       "      <td>53705</td>\n",
       "      <td>53716</td>\n",
       "      <td>49498</td>\n",
       "      <td>53716</td>\n",
       "      <td>53716</td>\n",
       "      <td>53716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>54388</td>\n",
       "      <td>51968</td>\n",
       "      <td>42754</td>\n",
       "      <td>4525</td>\n",
       "      <td>3</td>\n",
       "      <td>21143</td>\n",
       "      <td>176</td>\n",
       "      <td>905</td>\n",
       "      <td>3147</td>\n",
       "      <td>1092</td>\n",
       "      <td>...</td>\n",
       "      <td>900</td>\n",
       "      <td>157</td>\n",
       "      <td>907</td>\n",
       "      <td>141</td>\n",
       "      <td>470</td>\n",
       "      <td>63</td>\n",
       "      <td>29</td>\n",
       "      <td>131</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>MDP-349</td>\n",
       "      <td>9-Nov</td>\n",
       "      <td>TIDES (Lon 104.20508 Lat 2.78197)</td>\n",
       "      <td>Tioman Island, Pahang, Malaysia</td>\n",
       "      <td>Oecan Conservancy TIDES Report</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Tioman Island</td>\n",
       "      <td>Thur_Schoenenberg_SchaerA</td>\n",
       "      <td>...</td>\n",
       "      <td>Florida</td>\n",
       "      <td>United States</td>\n",
       "      <td>USFL</td>\n",
       "      <td>US</td>\n",
       "      <td>FL</td>\n",
       "      <td>State</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>Primary land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2037</td>\n",
       "      <td>2080</td>\n",
       "      <td>49849</td>\n",
       "      <td>2037</td>\n",
       "      <td>28501</td>\n",
       "      <td>8110</td>\n",
       "      <td>2080</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>8364</td>\n",
       "      <td>30964</td>\n",
       "      <td>8364</td>\n",
       "      <td>31970</td>\n",
       "      <td>8364</td>\n",
       "      <td>36011</td>\n",
       "      <td>48300</td>\n",
       "      <td>31970</td>\n",
       "      <td>37057</td>\n",
       "      <td>43124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UniqueID SourceID                     LocationFreqID  \\\n",
       "count     54388    51970                              54388   \n",
       "unique    54388    51968                              42754   \n",
       "top     MDP-349    9-Nov  TIDES (Lon 104.20508 Lat 2.78197)   \n",
       "freq          1        2                               2037   \n",
       "\n",
       "                               Location                         Dataset  \\\n",
       "count                             51142                           54388   \n",
       "unique                             4525                               3   \n",
       "top     Tioman Island, Pahang, Malaysia  Oecan Conservancy TIDES Report   \n",
       "freq                               2080                           49849   \n",
       "\n",
       "       Organization CountryName_FromSource SubCountry_L1_FromSource  \\\n",
       "count         43588                  50412                    48291   \n",
       "unique        21143                    176                      905   \n",
       "top       Despacito                    USA                  Florida   \n",
       "freq           2037                  28501                     8110   \n",
       "\n",
       "       SubCountry_L2_FromSource              ShorelineName  ...     NAME  \\\n",
       "count                     48724                       4539  ...    53716   \n",
       "unique                     3147                       1092  ...      900   \n",
       "top               Tioman Island  Thur_Schoenenberg_SchaerA  ...  Florida   \n",
       "freq                       2080                         58  ...     8364   \n",
       "\n",
       "              COUNTRY ISO_CODE ISO_CC ISO_SUB ADMINTYPE  NOTES     COUNTRYAFF  \\\n",
       "count           53716    53716  53715   53705     53716  49498          53716   \n",
       "unique            157      907    141     470        63     29            131   \n",
       "top     United States     USFL     US      FL     State         United States   \n",
       "freq            30964     8364  31970    8364     36011  48300          31970   \n",
       "\n",
       "            CONTINENT     LAND_TYPE  \n",
       "count           53716         53716  \n",
       "unique              8             4  \n",
       "top     North America  Primary land  \n",
       "freq            37057         43124  \n",
       "\n",
       "[4 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.describe(include=['object', \"bool\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e0fe968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>RecordSequenceID</th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>LocationFreqID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Organization</th>\n",
       "      <th>...</th>\n",
       "      <th>CONTINENT</th>\n",
       "      <th>LAND_TYPE</th>\n",
       "      <th>LAND_RANK</th>\n",
       "      <th>Shape__Area</th>\n",
       "      <th>Shape__Length</th>\n",
       "      <th>Count_</th>\n",
       "      <th>Soft_Sheets2</th>\n",
       "      <th>PlasticStraps2</th>\n",
       "      <th>FishingGlowSticks2</th>\n",
       "      <th>FishingOtherPlasticDebris2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54388.000000</td>\n",
       "      <td>54388.000000</td>\n",
       "      <td>54388.000000</td>\n",
       "      <td>54388.000000</td>\n",
       "      <td>54388</td>\n",
       "      <td>51970</td>\n",
       "      <td>54388</td>\n",
       "      <td>51142</td>\n",
       "      <td>54388</td>\n",
       "      <td>43588</td>\n",
       "      <td>...</td>\n",
       "      <td>53716</td>\n",
       "      <td>53716</td>\n",
       "      <td>53716.000000</td>\n",
       "      <td>53716.000000</td>\n",
       "      <td>53716.000000</td>\n",
       "      <td>54388.0</td>\n",
       "      <td>54388.000000</td>\n",
       "      <td>54388.000000</td>\n",
       "      <td>54388.000000</td>\n",
       "      <td>54388.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54388</td>\n",
       "      <td>51968</td>\n",
       "      <td>42754</td>\n",
       "      <td>4525</td>\n",
       "      <td>3</td>\n",
       "      <td>21143</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MDP-349</td>\n",
       "      <td>9-Nov</td>\n",
       "      <td>TIDES (Lon 104.20508 Lat 2.78197)</td>\n",
       "      <td>Tioman Island, Pahang, Malaysia</td>\n",
       "      <td>Oecan Conservancy TIDES Report</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>Primary land</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2037</td>\n",
       "      <td>2080</td>\n",
       "      <td>49849</td>\n",
       "      <td>2037</td>\n",
       "      <td>...</td>\n",
       "      <td>37057</td>\n",
       "      <td>43124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-50.623321</td>\n",
       "      <td>30.010745</td>\n",
       "      <td>27664.186751</td>\n",
       "      <td>31475.197249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.456791</td>\n",
       "      <td>20.262876</td>\n",
       "      <td>42.238083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.126554</td>\n",
       "      <td>3.337207</td>\n",
       "      <td>0.016272</td>\n",
       "      <td>0.325403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.093156</td>\n",
       "      <td>18.598370</td>\n",
       "      <td>15737.607977</td>\n",
       "      <td>17860.446270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.127345</td>\n",
       "      <td>35.415710</td>\n",
       "      <td>49.573144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.921683</td>\n",
       "      <td>39.447513</td>\n",
       "      <td>0.819717</td>\n",
       "      <td>8.762157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-174.018918</td>\n",
       "      <td>-62.918120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.035621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-95.305050</td>\n",
       "      <td>25.794117</td>\n",
       "      <td>14089.750000</td>\n",
       "      <td>15956.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.308655</td>\n",
       "      <td>7.218285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-80.051825</td>\n",
       "      <td>33.710430</td>\n",
       "      <td>27686.500000</td>\n",
       "      <td>31254.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.537436</td>\n",
       "      <td>32.360980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.859105</td>\n",
       "      <td>41.688923</td>\n",
       "      <td>41283.250000</td>\n",
       "      <td>47422.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.664867</td>\n",
       "      <td>56.814460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>178.733330</td>\n",
       "      <td>79.375890</td>\n",
       "      <td>54880.000000</td>\n",
       "      <td>61769.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>488.468405</td>\n",
       "      <td>1961.565144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>702.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   X             Y      OBJECTID  RecordSequenceID UniqueID  \\\n",
       "count   54388.000000  54388.000000  54388.000000      54388.000000    54388   \n",
       "unique           NaN           NaN           NaN               NaN    54388   \n",
       "top              NaN           NaN           NaN               NaN  MDP-349   \n",
       "freq             NaN           NaN           NaN               NaN        1   \n",
       "mean      -50.623321     30.010745  27664.186751      31475.197249      NaN   \n",
       "std        77.093156     18.598370  15737.607977      17860.446270      NaN   \n",
       "min      -174.018918    -62.918120      1.000000        349.000000      NaN   \n",
       "25%       -95.305050     25.794117  14089.750000      15956.750000      NaN   \n",
       "50%       -80.051825     33.710430  27686.500000      31254.500000      NaN   \n",
       "75%        -2.859105     41.688923  41283.250000      47422.250000      NaN   \n",
       "max       178.733330     79.375890  54880.000000      61769.000000      NaN   \n",
       "\n",
       "       SourceID                     LocationFreqID  \\\n",
       "count     51970                              54388   \n",
       "unique    51968                              42754   \n",
       "top       9-Nov  TIDES (Lon 104.20508 Lat 2.78197)   \n",
       "freq          2                               2037   \n",
       "mean        NaN                                NaN   \n",
       "std         NaN                                NaN   \n",
       "min         NaN                                NaN   \n",
       "25%         NaN                                NaN   \n",
       "50%         NaN                                NaN   \n",
       "75%         NaN                                NaN   \n",
       "max         NaN                                NaN   \n",
       "\n",
       "                               Location                         Dataset  \\\n",
       "count                             51142                           54388   \n",
       "unique                             4525                               3   \n",
       "top     Tioman Island, Pahang, Malaysia  Oecan Conservancy TIDES Report   \n",
       "freq                               2080                           49849   \n",
       "mean                                NaN                             NaN   \n",
       "std                                 NaN                             NaN   \n",
       "min                                 NaN                             NaN   \n",
       "25%                                 NaN                             NaN   \n",
       "50%                                 NaN                             NaN   \n",
       "75%                                 NaN                             NaN   \n",
       "max                                 NaN                             NaN   \n",
       "\n",
       "       Organization  ...      CONTINENT     LAND_TYPE     LAND_RANK  \\\n",
       "count         43588  ...          53716         53716  53716.000000   \n",
       "unique        21143  ...              8             4           NaN   \n",
       "top       Despacito  ...  North America  Primary land           NaN   \n",
       "freq           2037  ...          37057         43124           NaN   \n",
       "mean            NaN  ...            NaN           NaN      4.456791   \n",
       "std             NaN  ...            NaN           NaN      1.127345   \n",
       "min             NaN  ...            NaN           NaN      2.000000   \n",
       "25%             NaN  ...            NaN           NaN      5.000000   \n",
       "50%             NaN  ...            NaN           NaN      5.000000   \n",
       "75%             NaN  ...            NaN           NaN      5.000000   \n",
       "max             NaN  ...            NaN           NaN      5.000000   \n",
       "\n",
       "         Shape__Area  Shape__Length   Count_  Soft_Sheets2  PlasticStraps2  \\\n",
       "count   53716.000000   53716.000000  54388.0  54388.000000    54388.000000   \n",
       "unique           NaN            NaN      NaN           NaN             NaN   \n",
       "top              NaN            NaN      NaN           NaN             NaN   \n",
       "freq             NaN            NaN      NaN           NaN             NaN   \n",
       "mean       20.262876      42.238083      1.0      0.126554        3.337207   \n",
       "std        35.415710      49.573144      0.0      2.921683       39.447513   \n",
       "min         0.000057       0.035621      1.0      0.000000        0.000000   \n",
       "25%         0.308655       7.218285      1.0      0.000000        0.000000   \n",
       "50%        10.537436      32.360980      1.0      0.000000        0.000000   \n",
       "75%        20.664867      56.814460      1.0      0.000000        0.000000   \n",
       "max       488.468405    1961.565144      1.0    258.000000     3974.000000   \n",
       "\n",
       "        FishingGlowSticks2  FishingOtherPlasticDebris2  \n",
       "count         54388.000000                54388.000000  \n",
       "unique                 NaN                         NaN  \n",
       "top                    NaN                         NaN  \n",
       "freq                   NaN                         NaN  \n",
       "mean              0.016272                    0.325403  \n",
       "std               0.819717                    8.762157  \n",
       "min               0.000000                    0.000000  \n",
       "25%               0.000000                    0.000000  \n",
       "50%               0.000000                    0.000000  \n",
       "75%               0.000000                    0.000000  \n",
       "max             124.000000                  702.000000  \n",
       "\n",
       "[11 rows x 83 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9d92f",
   "metadata": {},
   "source": [
    "### Value_Counts - df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a20b7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc662fe",
   "metadata": {},
   "source": [
    "### Correlation Analysis - df.corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68ff064a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.corr of       End of Period Loan Number                       Region Country Code  \\\n",
       "0         6/30/2020   IBRD01240  LATIN AMERICA AND CARIBBEAN           GT   \n",
       "1         6/30/2020   IBRD04870  LATIN AMERICA AND CARIBBEAN           GT   \n",
       "2         6/30/2020   IBRD05450  LATIN AMERICA AND CARIBBEAN           GT   \n",
       "3         6/30/2020   IBRD05760  LATIN AMERICA AND CARIBBEAN           GT   \n",
       "4         6/30/2020   IBRD07220  LATIN AMERICA AND CARIBBEAN           GT   \n",
       "...             ...         ...                          ...          ...   \n",
       "89688         44135   IBRD43170  LATIN AMERICA AND CARIBBEAN           VE   \n",
       "89689         44135   IBRD44000  LATIN AMERICA AND CARIBBEAN           VE   \n",
       "89690         44135   IBRD45030  LATIN AMERICA AND CARIBBEAN           VE   \n",
       "89691         44135   IBRD45720  LATIN AMERICA AND CARIBBEAN           VE   \n",
       "89692         44135   IBRD70620  LATIN AMERICA AND CARIBBEAN           VE   \n",
       "\n",
       "         Country                         Borrower  Guarantor Loan Type  \\\n",
       "0      Guatemala  Ministerio de Finanzas Públicas  Guatemala       NPL   \n",
       "1      Guatemala   INSTITUTO NACIONAL DE ELECTRIF  Guatemala       NPL   \n",
       "2      Guatemala   INSTITUTO NACIONAL DE ELECTRIF  Guatemala       NPL   \n",
       "3      Guatemala  Ministerio de Finanzas Públicas  Guatemala       NPL   \n",
       "4      Guatemala  Ministerio de Finanzas Públicas  Guatemala       NPL   \n",
       "...          ...                              ...        ...       ...   \n",
       "89688  Venezuela           MINISTERIO DE FINANZAS  Venezuela       SCL   \n",
       "89689  Venezuela           MINISTERIO DE FINANZAS  Venezuela       SCL   \n",
       "89690  Venezuela           MINISTERIO DE FINANZAS  Venezuela       SCL   \n",
       "89691  Venezuela           MINISTERIO DE FINANZAS  Venezuela       SCL   \n",
       "89692  Venezuela           MINISTERIO DE FINANZAS  Venezuela       FSL   \n",
       "\n",
       "           Loan Status Interest Rate Project ID  \\\n",
       "0         Fully Repaid          4.63    P007179   \n",
       "1         Fully Repaid             6    P007180   \n",
       "2         Fully Repaid          6.25    P007181   \n",
       "3         Fully Repaid           6.5    P007182   \n",
       "4         Fully Repaid          7.25    P007183   \n",
       "...                ...           ...        ...   \n",
       "89688  Fully Cancelled          4.89    P041807   \n",
       "89689     Fully Repaid          5.61    P040174   \n",
       "89690     Fully Repaid          5.09    P057601   \n",
       "89691     Fully Repaid          5.79    P066749   \n",
       "89692     Fully Repaid          -       P050495   \n",
       "\n",
       "                           Project Name      Credit_Line        Cancelled  \\\n",
       "0                               HIGHWAY    18,200,000.00           -        \n",
       "1                  POWER I (JURUN-MAUNA    15,000,000.00           765.39   \n",
       "2                  POWER II (ESCUINTLA)     7,000,000.00           -        \n",
       "3                             EDUCATION     6,300,000.00           -        \n",
       "4                             LIVESTOCK     4,000,000.00           -        \n",
       "...                                 ...              ...              ...   \n",
       "89688   VENEZUELA PUB SEC LEG & ADM MOD   $8,000,000.00    $8,000,000.00    \n",
       "89689           VE CARACAS SLUM UPGRADE  $60,700,000.00   $29,001,347.53    \n",
       "89690  VE PUBLIC EXPENDITURE MANAGEMENT  $20,000,000.00    $7,825,840.56    \n",
       "89691  VE MILLENNIUM SCIENCE INITIATIVE   $5,000,000.00      $233,537.18    \n",
       "89692  VE-  CARACAS METROPOLITAN HEALTH  $30,300,000.00   $26,444,937.03    \n",
       "\n",
       "             Disbursed Sold 3rd Party Agreement Signing Date Closed Date  \n",
       "0        18,200,000.00   2,731,000.00              7/29/1955  12/31/1960  \n",
       "1        14,999,234.61      50,000.00              3/10/1967  12/31/1972  \n",
       "2         7,000,000.00         -                   6/28/1968  12/31/1974  \n",
       "3         6,300,000.00         -                  12/16/1968   7/31/1975  \n",
       "4         4,000,000.00     303,194.45              2/10/1971   6/30/1978  \n",
       "...                ...            ...                    ...         ...  \n",
       "89688            -              -                      36145       38808  \n",
       "89689  $31,698,652.47           -                      36145       38898  \n",
       "89690  $12,284,556.28           -                      36616       38898  \n",
       "89691   $4,766,462.82           -                      36937       38352  \n",
       "89692   $3,855,062.97           -                      37246       39082  \n",
       "\n",
       "[89693 rows x 18 columns]>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efe59e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e6a7ffa",
   "metadata": {},
   "source": [
    "# STAGE 2: Data Structuring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296754d",
   "metadata": {},
   "source": [
    "When raw data is collected, it’s in a wide range of formats and sizes. It has no definite structure, which means that it lacks an existing model and is completely disorganized. It needs to be restructured to fit in with the Analytical Model deployed by your business, and giving it a structure allows for better analysis. \n",
    "\n",
    "Unstructured data is often text-heavy and contains things such as Dates, Numbers, ID codes, etc. At this stage of the Data Wrangling process, the dataset needs to be parsed.\n",
    "https://hevodata.com/learn/data-wrangling/#s2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ba4f5",
   "metadata": {},
   "source": [
    "### Rename Columns - df.rename({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pollution_00 = df_pollution.rename({\n",
    "                   'NAME':'State',\n",
    "                   'COUNTRYAFF':'Country',\n",
    "                   'CONTINENT':'Continent',\n",
    "                   'RecordSequenceID':'Record',\n",
    "                   'Longitude1':'Longitude',\n",
    "                   'Latitude1':'Latitude',\n",
    "                   'ShorelineName':'Adress',\n",
    "                   'MonthNumber':'Month',\n",
    "                   \"SUM_FishingLineLureRope\":\"FishingLineLureRope\",\n",
    "                   \"SUM_Foam_OtherPlasticDebris\":\"FoamOtherPlasticDebris\",\n",
    "                   \"SUM_Hard_BucketOrCrate\":\"HardBucketOrCrate\",   \n",
    "                   \"SUM_Hard_Lighter\":\"HardLighter\",\n",
    "                   \"SUM_Hard_OtherPlasticBottle\":\"HardOtherPlasticBottle\",\n",
    "                   \"SUM_Hard_PlasticBeverageBottle\":\"HardPlasticBeverageBottle\",\n",
    "                   \"SUM_HardOrSoft_PlasticBottleCap\":\"HardOrSoftPlasticBottleCap\",\n",
    "                   \"SUM_HardSoft_PersonalCareProduc\":\"HardSoftPersonalCareProduc\",\n",
    "                   \"SUM_HardSoftLollipopStick_EarBu\":\"HardSoftLollipopStickEarBu\",\n",
    "                   \"SUM_OtherHardPlastic\":\"OtherHardPlastic\",\n",
    "                   \"SUM_OtherPlasticDebris\":\"OtherPlasticDebris\",\n",
    "                   \"SUM_PlasticOrFoamFoodContainer\":\"PlasticOrFoamFoodContainer\",\n",
    "                   \"SUM_PlasticOrFoamPlatesBowlsCup\":\"PlasticOrFoamPlatesBowlsCup\",\n",
    "                   \"SUM_Soft_Bag\":\"SoftBag\",\n",
    "                   \"SUM_Soft_CigaretteButts\":\"SoftCigaretteButts\",\n",
    "                   \"SUM_Soft_OtherPlastic\":\"SoftOtherPlastic\",\n",
    "                   \"SUM_Soft_Straw\":\"SoftStraw\",\n",
    "                   \"SUM_Soft_StringRingRibbon\":\"SoftStringRingRibbon\",\n",
    "                   \"SUM_Soft_WrapperOrLabel\":\"SoftWrapperOrLabel\",\n",
    "                   \"Soft_Sheets2\":\"SoftSheets\",\n",
    "                   \"PlasticStraps2\":\"PlasticStraps\",\n",
    "                   \"FishingGlowSticks2\":\"FishingGlowSticks\",\n",
    "                   \"FishingOtherPlasticDebris2\":\"FishingOtherPlasticDebris\",\n",
    "                   },\n",
    "                  axis = 1\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Verify last action - Best practice\n",
    "df_pollution_00.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e88c6d2",
   "metadata": {},
   "source": [
    "### Rearrange Columns - df[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a32bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df02 = df_pollution_00[[\n",
    "            'Record',\n",
    "            'Longitude', \n",
    "            'Latitude', \n",
    "            'Continent',\n",
    "            'Country',\n",
    "            'State',\n",
    "            'Adress', \n",
    "            'Year', \n",
    "            'HardPlasticBeverageBottle', \n",
    "            'HardOtherPlasticBottle',\n",
    "            'HardOrSoftPlasticBottleCap', \n",
    "            'PlasticOrFoamFoodContainer',\n",
    "            'HardBucketOrCrate', \n",
    "            'HardLighter', \n",
    "            'OtherHardPlastic',\n",
    "            'PlasticOrFoamPlatesBowlsCup', \n",
    "            'HardSoftPersonalCareProduc',\n",
    "            'HardSoftLollipopStickEarBu',\n",
    "            'SoftBag', \n",
    "            'SoftWrapperOrLabel',\n",
    "            'SoftStraw', \n",
    "            'SoftOtherPlastic', \n",
    "            'SoftCigaretteButts',\n",
    "            'SoftStringRingRibbon', \n",
    "            'Fishing_Net', \n",
    "            'FishingLineLureRope',\n",
    "            'Fishing_BuoysAndFloats',\n",
    "            'FoamOtherPlasticDebris',\n",
    "            'OtherPlasticDebris',\n",
    "            'SoftSheets',\n",
    "            'PlasticStraps',\n",
    "            'FishingGlowSticks',\n",
    "            'FishingOtherPlasticDebris']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ae043",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Verify last action - Best practice\n",
    "df02.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af04b4",
   "metadata": {},
   "source": [
    "### Text Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93802e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(\n",
    "    ['Srinivas', 'DATAhill', '9292005440','Hyderabad', 'info@datahill.in', 'dataanalysis', 'PYTHON','Pandas']\n",
    "     )\n",
    "\n",
    "# s.str.islower()\n",
    "s = pd.Series(['hello', 'world', 'Python', 'is', 'AWESOME'])\n",
    "print(s.str.islower())\n",
    "\n",
    "#s.str.lower()\n",
    "s = pd.Series(['Hello', 'WORLD', 'Python', 'is', 'AWESOME'])\n",
    "s_lower = s.str.lower()\n",
    "print(s_lower)\n",
    "\n",
    "#s.str.isupper()\n",
    "s = pd.Series(['HELLO', 'WORLD', 'Python', 'IS', 'AWESOME'])\n",
    "print(s.str.isupper())\n",
    "\n",
    "#s.str.upper()\n",
    "s = pd.Series(['Hello', 'WORLD', 'Python', 'is', 'awesome'])\n",
    "s_upper = s.str.upper()\n",
    "print(s_upper)\n",
    "\n",
    "#s.str.isnumeric()\n",
    "s = pd.Series(['123', '45.6', '789', 'one', 'two', 'three'])\n",
    "print(s.str.isnumeric())\n",
    "\n",
    "#s.str.swapcase()\n",
    "s = pd.Series(['aPPle', 'bAnaNa', 'CHERRY', 'dATE', 'ELDERBERRY'])\n",
    "s_swapped_case = s.str.swapcase()\n",
    "print(s_swapped_case)\n",
    "\n",
    "#s.str.len()\n",
    "s = pd.Series(['apple', 'banana', 'cherry', 'date', 'elderberry'])\n",
    "s_length = s.str.len()\n",
    "print(s_length)\n",
    "\n",
    "#s.str.cat(sep='_')\n",
    "s = pd.Series(['apple', 'banana', 'cherry', 'date', 'elderberry'])\n",
    "s_concatenated = s.str.cat(sep='_')\n",
    "print(s_concatenated)\n",
    "\n",
    "#s.str.replace('@','$')\n",
    "s = pd.Series(['example@domain.com', 'user@gmail.com', 'customer@yahoo.com'])\n",
    "s_replaced = s.str.replace('@', '$')\n",
    "print(s_replaced)\n",
    "\n",
    "#s.str.repeat(2)\n",
    "s = pd.Series(['apple', 'banana', 'cherry', 'date', 'elderberry'])\n",
    "s_repeated = s.str.repeat(2)\n",
    "print(s_repeated)\n",
    "\n",
    "#s.str.count('s')\n",
    "s = pd.Series(['apple', 'banana', 'cherry', 'date', 'elderberry'])\n",
    "s_count = s.str.count('e')\n",
    "print(s_count)\n",
    "\n",
    "#s.str.startswith ('P')\n",
    "s = pd.Series(['Python', 'Java', 'C++', 'Perl', 'PHP'])\n",
    "s_starts_with_p = s.str.startswith('P')\n",
    "print(s_starts_with_p)\n",
    "\n",
    "#s.str.endswith('s')\n",
    "s = pd.Series(['apple', 'banana', 'cherry', 'dates', 'elderberry'])\n",
    "s_ends_with_s = s.str.endswith('s')\n",
    "print(s_ends_with_s)\n",
    "\n",
    "#### DELETE BLANK_SPACES (strip)\n",
    "df_Mes['Mes'] = df_Mes['Mes'].str.strip()\n",
    "\n",
    "#### SPLIT - .str.split\n",
    "\n",
    "# Textual data usually contains multiple pieces of information.\n",
    "# The str accessor of Pandas provides numerous function to perform such\n",
    "# operations efficiently.\n",
    "\n",
    "# The last characters represent the type of location. For instance, “st”\n",
    "# stands for street and “dr” stands for drive. It can be a useful piece of\n",
    "# information for grouping the addresses.\n",
    "\n",
    "# Before:\n",
    "    \n",
    "melb.Address[:5] # melb 0 df, Address = Col\n",
    "0        85 Turner St \n",
    "1     25 Bloomburg St \n",
    "2        5 Charles St \n",
    "3    40 Federation La \n",
    "4         55a Park St \n",
    "Name: Address, dtype: object\n",
    "\n",
    "# After:\n",
    "    \n",
    "melb['Address'].str.split(' ').str[-1]\n",
    "0    St \n",
    "1    St \n",
    "2    St \n",
    "3    La \n",
    "4    St "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effea523",
   "metadata": {},
   "source": [
    "### Date & Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create date\n",
    "\n",
    "# Frequence by Days\n",
    "dates_d = pd.date_range('20191110', periods=10, freq='D')\n",
    "# Frequence by Months\n",
    "dates_m = pd.date_range('20191110', periods=10, freq='M')\n",
    "# Create data with date\n",
    "df = pd.DataFrame(random, index=dates_m, columns=list('ABCD'))\n",
    "\n",
    "# Demistify timestamp format into datetime-categories\n",
    "from datetime import datetime \n",
    "datetime.strptime('2018-04-29T17:45:25Z', '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "from dateutil.parser import parse\n",
    "parse('2018-04-29T17:45:25Z')\n",
    "\n",
    "import arrow \n",
    "arrow.get('2018-04-29T17:45:25Z').datetime\n",
    "\n",
    "import moment\n",
    "moment.date(\"tomorrow\")\n",
    "\n",
    "import maya\n",
    "maya.parse('2018-04-29T17:45:25Z').slang_time()\n",
    "\n",
    "# Datetime_tutorials\n",
    "    # https://www.geeksforgeeks.org/python-datetime-module/\n",
    "\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "print(\"Today's date is\", today)\n",
    "\n",
    "from datetime import datetime\n",
    "# Calling now() function\n",
    "today = datetime.now()\n",
    "print(\"Current date and time is\", today)\n",
    "\n",
    "# Convert datetime to string format\n",
    "from datetime import datetime as dt\n",
    "# Getting current date and time\n",
    "now = dt.now()\n",
    "string = dt.isoformat(now)\n",
    "print(string)\n",
    "print(type(string))\n",
    "\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "print(\"Current year:\", today.year)\n",
    "print(\"Current month:\", today.month)\n",
    "print(\"Current day:\", today.day)\n",
    "\n",
    "from datetime import time\n",
    "Time = time(11, 34, 56)\n",
    "print(\"hour =\", Time.hour)\n",
    "print(\"minute =\", Time.minute)\n",
    "print(\"second =\", Time.second)\n",
    "print(\"microsecond =\", Time.microsecond)\n",
    "\n",
    "from datetime import datetime\n",
    "a = datetime(1999, 12, 12, 12, 12, 12)\n",
    "print(\"year =\", a.year)\n",
    "print(\"month =\", a.month)\n",
    "print(\"hour =\", a.hour)\n",
    "print(\"minute =\", a.minute)\n",
    "print(\"timestamp =\", a.timestamp())\n",
    "\n",
    "from datetime import datetime\n",
    "# Getting Datetime from timestamp\n",
    "date_time = datetime.fromtimestamp(1887639468)\n",
    "print(\"Datetime from timestamp:\", date_time)\n",
    "\n",
    "# Calculating future dates\n",
    "from datetime import datetime, timedelta\n",
    "# Using current time\n",
    "ini_time_for_now = datetime.now()\n",
    "# printing initial_date\n",
    "print(\"initial_date\", str(ini_time_for_now))\n",
    "# Calculating future dates for two years\n",
    "future_date_after_2yrs = ini_time_for_now + timedelta(days=730)\n",
    "future_date_after_2days = ini_time_for_now + timedelta(days=2)\n",
    "# printing calculated future_dates\n",
    "print('future_date_after_2yrs:', str(future_date_after_2yrs))\n",
    "print('future_date_after_2days:', str(future_date_after_2days))\n",
    "\n",
    "# Difference between two date and times\n",
    "from datetime import datetime, timedelta\n",
    "# Using current time\n",
    "ini_time_for_now = datetime.now()\n",
    "# printing initial_date\n",
    "print(\"initial_date\", str(ini_time_for_now))\n",
    "# Some another datetime\n",
    "new_final_time = ini_time_for_now + \\\n",
    "    timedelta(days=2)\n",
    "# printing new final_date\n",
    "print(\"new_final_time\", str(new_final_time))\n",
    "# printing calculated past_dates\n",
    "print('Time difference:', str(new_final_time -\n",
    "                              ini_time_for_now))\n",
    "\n",
    "# Apply date format to datetime operations\n",
    "from datetime import datetime as dt\n",
    "# Getting current date and time\n",
    "now = dt.now()\n",
    "print(\"Without formatting\", now)\n",
    "# Example 1\n",
    "s = now.strftime(\"%A %m %-Y\")\n",
    "print('\\nExample 1:', s)\n",
    "# Example 2\n",
    "s = now.strftime(\"%a %-m %y\")\n",
    "print('\\nExample 2:', s)\n",
    "# Example 3\n",
    "s = now.strftime(\"%-I %p %S\")\n",
    "print('\\nExample 3:', s) \n",
    "# Example 4\n",
    "s = now.strftime(\"%H:%M:%S\")\n",
    "print('\\nExample 4:', s)\n",
    "\n",
    "# import datetime module from datetime\n",
    "from datetime import datetime\n",
    "# consider the time stamps from a list  in string\n",
    "# format DD/MM/YY H:M:S.micros\n",
    "time_data = [\"25/05/99 02:35:8.023\", \"26/05/99 12:45:0.003\",\n",
    "             \"27/05/99 07:35:5.523\", \"28/05/99 05:15:55.523\"] \n",
    "# format the string in the given format : day/month/year \n",
    "# hours/minutes/seconds-micro seconds\n",
    "format_data = \"%d/%m/%y %H:%M:%S.%f\"\n",
    "# Using strptime with datetime we will format string\n",
    "# into datetime\n",
    "for i in time_data:\n",
    "    print(datetime.strptime(i, format_data))\n",
    "# Timezone_tutorials\n",
    "    # https://www.geeksforgeeks.org/python-pytz/\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import datetime, date, time, timedelta\n",
    "\n",
    "path = r'C:\\Users\\Asus VivoBook\\Dropbox\\My PC (DESKTOP-GN5CQHE)\\Documents\\My Studies\\PowerUp Institute\\Python\\week 04\\BDTienda.csv'\n",
    "df = pd.read_csv(path,sep=',',header=0,index_col=False,\n",
    "                 encoding='latin-1',engine='python',\n",
    "                 parse_dates=['Order Date','Ship Date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbffd84",
   "metadata": {},
   "source": [
    "\n",
    "# STAGE 3: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5ef999",
   "metadata": {},
   "source": [
    "Most people use the words Data Wrangling and Data Cleaning interchangeably. However, these are two very different processes. Although a complex process in itself, Cleaning is just a single aspect of the overall Data Wrangling process.\n",
    "\n",
    "For the most part, raw data comes with a lot of errors that have to be cleaned before the data can move on to the next stage. Data Cleaning involves Tackling Outliers, Making Corrections, Deleting Bad Data completely, etc. This is done by applying algorithms to tidy up and sanitize the dataset.\n",
    "\n",
    "Cleaning the data does the following:\n",
    "\n",
    "It removes outliers from your dataset that can potentially skew your results when analyzing the data. \n",
    "It changes any null values and standardizes the data format to improve quality and consistency.\n",
    "It identifies duplicate values and standardizes systems of measurements, fixes structural errors and typos, and validates the data to make it easier to handle.\n",
    "\n",
    "https://hevodata.com/learn/data-wrangling/#s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Read the df and Consult the Schema\n",
    "df_pollution = df_csv\n",
    "df_pollution.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7704afc",
   "metadata": {},
   "source": [
    "Most people use the words Data Wrangling and Data Cleaning interchangeably. However, these are two very different processes. Although a complex process in itself, Cleaning is just a single aspect of the overall Data Wrangling process.\n",
    "\n",
    "For the most part, raw data comes with a lot of errors that have to be cleaned before the data can move on to the next stage. Data Cleaning involves Tackling Outliers, Making Corrections, Deleting Bad Data completely, etc. This is done by applying algorithms to tidy up and sanitize the dataset.\n",
    "\n",
    "Cleaning the data does the following:\n",
    "\n",
    "It removes outliers from your dataset that can potentially skew your results when analyzing the data. \n",
    "It changes any null values and standardizes the data format to improve quality and consistency.\n",
    "It identifies duplicate values and standardizes systems of measurements, fixes structural errors and typos, and validates the data to make it easier to handle.\n",
    "\n",
    "https://hevodata.com/learn/data-wrangling/#s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deadd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid unnecesary Columns\n",
    "\n",
    "df_pollution.drop([\"X\", \"Y\",\n",
    "                 \"StartTime\",\n",
    "                 \"OBJECTID\", \n",
    "                 \"UniqueID\", \n",
    "                 \"SourceID\", \n",
    "                 \"LocationFreqID\", \n",
    "                 \"Location\", \n",
    "                 \"Dataset\", \n",
    "                 \"Organization\", \n",
    "                 \"Other\", \n",
    "                 \"CountryName_FromSource\", \n",
    "                 \"SubCountry_L1_FromSource\", \n",
    "                 \"SubCountry_L2_FromSource\", \n",
    "                 \"Longitude2\", \n",
    "                 \"Latitude2\", \n",
    "                 \"TotalWidth_m\", \n",
    "                 \"TotalLength_m\", \n",
    "                 \"TotalArea_Sq_m\", \n",
    "                 \"WaterfrontName\", \n",
    "                 \"BeachAreaLandcover\", \n",
    "                 \"BeachType\", \n",
    "                 \"TotalVolunteers\",\n",
    "                 \"DateOriginal\", \n",
    "                 \"DateStandardized\", \n",
    "                 \"MonthYear\", \n",
    "                 \"Month\", \n",
    "                 \"Day\", \n",
    "                 \"FieldObsevations\", \n",
    "                 \"DebrisDescription\", \n",
    "                 \"Totalltems_EventRecord\", \n",
    "                 \"TotalClassifiedItems_EC2020\", \n",
    "                 \"PCT_PlasticAndFoam\", \n",
    "                 \"PCT_Glass_Rubber_Lumber_Metal\", \n",
    "                 \"COUNTRY\", \n",
    "                 \"ISO_CODE\", \n",
    "                 \"ISO_CC\", \n",
    "                 \"ISO_SUB\", \n",
    "                 \"ADMINTYPE\", \n",
    "                 \"DISPUTED\", \n",
    "                 \"NOTES\", \n",
    "                 \"AUTONOMOUS\", \n",
    "                 \"LAND_TYPE\", \n",
    "                 \"LAND_RANK\", \n",
    "                 \"Shape__Area\", \n",
    "                 \"Shape__Length\", \n",
    "                 \"Count_\",\n",
    "                 \"EventType\"], \n",
    "                axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d32e408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54388 entries, 0 to 54387\n",
      "Data columns (total 35 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   RecordSequenceID                 54388 non-null  int64  \n",
      " 1   Longitude1                       54388 non-null  float64\n",
      " 2   Latitude1                        54388 non-null  float64\n",
      " 3   ShorelineName                    4539 non-null   object \n",
      " 4   Year                             54388 non-null  int64  \n",
      " 5   MonthNum                         54388 non-null  int64  \n",
      " 6   DOW                              54388 non-null  object \n",
      " 7   SUM_Hard_PlasticBeverageBottle   54388 non-null  int64  \n",
      " 8   SUM_Hard_OtherPlasticBottle      54388 non-null  int64  \n",
      " 9   SUM_HardOrSoft_PlasticBottleCap  54388 non-null  int64  \n",
      " 10  SUM_PlasticOrFoamFoodContainer   53580 non-null  float64\n",
      " 11  SUM_Hard_BucketOrCrate           54388 non-null  int64  \n",
      " 12  SUM_Hard_Lighter                 53302 non-null  float64\n",
      " 13  SUM_OtherHardPlastic             54388 non-null  int64  \n",
      " 14  SUM_PlasticOrFoamPlatesBowlsCup  54388 non-null  int64  \n",
      " 15  SUM_HardSoft_PersonalCareProduc  54388 non-null  int64  \n",
      " 16  SUM_HardSoftLollipopStick_EarBu  54388 non-null  int64  \n",
      " 17  SUM_Soft_Bag                     54388 non-null  int64  \n",
      " 18  SUM_Soft_WrapperOrLabel          54388 non-null  int64  \n",
      " 19  SUM_Soft_Straw                   53489 non-null  float64\n",
      " 20  SUM_Soft_OtherPlastic            54388 non-null  int64  \n",
      " 21  SUM_Soft_CigaretteButts          53849 non-null  float64\n",
      " 22  SUM_Soft_StringRingRibbon        54388 non-null  int64  \n",
      " 23  Fishing_Net                      54388 non-null  int64  \n",
      " 24  SUM_FishingLineLureRope          54388 non-null  int64  \n",
      " 25  Fishing_BuoysAndFloats           54388 non-null  int64  \n",
      " 26  SUM_Foam_OtherPlasticDebris      54388 non-null  int64  \n",
      " 27  SUM_OtherPlasticDebris           51970 non-null  float64\n",
      " 28  NAME                             53716 non-null  object \n",
      " 29  COUNTRYAFF                       53716 non-null  object \n",
      " 30  CONTINENT                        53716 non-null  object \n",
      " 31  Soft_Sheets2                     54388 non-null  int64  \n",
      " 32  PlasticStraps2                   54388 non-null  int64  \n",
      " 33  FishingGlowSticks2               54388 non-null  int64  \n",
      " 34  FishingOtherPlasticDebris2       54388 non-null  int64  \n",
      "dtypes: float64(7), int64(23), object(5)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "####### Verify Columns Deletion - Best practice\n",
    "df_pollution.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e9c991",
   "metadata": {},
   "source": [
    "### Null Values - df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16d052e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecordSequenceID                       0\n",
       "Longitude1                             0\n",
       "Latitude1                              0\n",
       "ShorelineName                      49849\n",
       "Year                                   0\n",
       "MonthNum                               0\n",
       "DOW                                    0\n",
       "SUM_Hard_PlasticBeverageBottle         0\n",
       "SUM_Hard_OtherPlasticBottle            0\n",
       "SUM_HardOrSoft_PlasticBottleCap        0\n",
       "SUM_PlasticOrFoamFoodContainer       808\n",
       "SUM_Hard_BucketOrCrate                 0\n",
       "SUM_Hard_Lighter                    1086\n",
       "SUM_OtherHardPlastic                   0\n",
       "SUM_PlasticOrFoamPlatesBowlsCup        0\n",
       "SUM_HardSoft_PersonalCareProduc        0\n",
       "SUM_HardSoftLollipopStick_EarBu        0\n",
       "SUM_Soft_Bag                           0\n",
       "SUM_Soft_WrapperOrLabel                0\n",
       "SUM_Soft_Straw                       899\n",
       "SUM_Soft_OtherPlastic                  0\n",
       "SUM_Soft_CigaretteButts              539\n",
       "SUM_Soft_StringRingRibbon              0\n",
       "Fishing_Net                            0\n",
       "SUM_FishingLineLureRope                0\n",
       "Fishing_BuoysAndFloats                 0\n",
       "SUM_Foam_OtherPlasticDebris            0\n",
       "SUM_OtherPlasticDebris              2418\n",
       "NAME                                 672\n",
       "COUNTRYAFF                           672\n",
       "CONTINENT                            672\n",
       "Soft_Sheets2                           0\n",
       "PlasticStraps2                         0\n",
       "FishingGlowSticks2                     0\n",
       "FishingOtherPlasticDebris2             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Detect & Summarize <Null Values>\n",
    "nulls = df_pollution.isna().sum()\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify last action - Best Practrice\n",
    "validate_NA_values = df_pollution.isna().sum()\n",
    "validate_NA_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6673dc84",
   "metadata": {},
   "source": [
    "### Replace Null Values - fillna()      {parameters: <\"NA\",0>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa7a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Method_01:\n",
    "# Fill <empty_values> with <NA>\n",
    "# This action applies for Columns whose attributes are \"objects\", this means they keep string values)\n",
    "df_pollution[\"ShorelineName\"].fillna(\"NA\", inplace = True)\n",
    "df_pollution[\"NAME\"].fillna(\"NA\", inplace = True)\n",
    "df_pollution[\"COUNTRYAFF\"].fillna(\"NA\", inplace = True)\n",
    "df_pollution[\"CONTINENT\"].fillna(\"NA\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd99282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Method_02:\n",
    "# Fill <empty_values> with <0>\n",
    "df_pollution[\"SUM_PlasticOrFoamFoodContainer\"].fillna(0, inplace=True)\n",
    "df_pollution[\"SUM_Hard_Lighter\"].fillna(0, inplace=True)\n",
    "df_pollution[\"SUM_Soft_Straw\"].fillna(0, inplace=True)\n",
    "df_pollution[\"SUM_Soft_CigaretteButts\"].fillna(0, inplace=True)\n",
    "df_pollution[\"SUM_OtherPlasticDebris\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d966447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Verify last action - Best Practice\n",
    "validate_NA_values = df_pollution.isna().sum()\n",
    "validate_NA_values\n",
    "# alternatively, the following snippet produce the same result \n",
    "# df01_na_values_T_or_F = df01_na_values >= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7482d19d",
   "metadata": {},
   "source": [
    "### Eliminate Null Values - dropna()\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop Duplicates - df.drop.duplicates\n",
    "Delete Duplicate Values = \"Project Name\"\n",
    "new_df = df.drop_duplicates(subset='Project Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Outliers\n",
    "low = np.quantile(marketing.Salary, 0.05)\n",
    "high = np.quantile(marketing.Salary, 0.95)\n",
    "marketing = marketing[marketing.Salary.between(low, high)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79379ef2",
   "metadata": {},
   "source": [
    "# STAGE 4: Data Enriching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f0bcc5",
   "metadata": {},
   "source": [
    "At this stage of the Data Wrangling process, you’ve become familiar with, and have a deep understanding of the data at hand. \n",
    "\n",
    "Now the question is, do you want to embellish or enrich the data? Do you want it augmented with other data?\n",
    "\n",
    "Combining your raw data with additional data from other sources such as internal systems, third-party providers, etc. will help you accumulate even more data points to improve the accuracy of your analysis. Alternatively, your goal might be to simply fill in gaps in the data. For instance, combining two databases of customer information where one contains customer addresses, and the other one doesn’t. \n",
    "\n",
    "Enriching the data is an optional step that you only need to take if your current data doesn’t meet your requirements.\n",
    "\n",
    "https://hevodata.com/learn/data-wrangling/#s2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a4b8a3",
   "metadata": {},
   "source": [
    "### Calculated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12916339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus VivoBook\\AppData\\Local\\Temp\\ipykernel_19520\\3665055.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df02['Total_PCare'] = df02['HardSoftPersonalCareProduc']\n"
     ]
    }
   ],
   "source": [
    "df02['Total_PCare'] = df02['HardSoftPersonalCareProduc']\n",
    "\n",
    "df02['Total_CigLig'] = df02['SoftCigaretteButts'] + df02['HardLighter']\n",
    "\n",
    "df02['Total_Bags'] = df02['SoftBag'] + df02['SoftSheets'] + df02['SoftWrapperOrLabel']\n",
    "\n",
    "df02['Total_HF_Plast'] = df02['HardOtherPlasticBottle'] + df02['PlasticOrFoamFoodContainer'] + df02['HardPlasticBeverageBottle'] + df02['HardOrSoftPlasticBottleCap'] + df02['HardBucketOrCrate'] + df02['PlasticOrFoamPlatesBowlsCup']  \n",
    "\n",
    "df02['Total_PDebris'] = df02['HardSoftLollipopStickEarBu'] + df02['SoftStraw'] + df02['OtherPlasticDebris'] + df02['SoftOtherPlastic'] + df02['FoamOtherPlasticDebris'] + df02['OtherHardPlastic']\n",
    "                                          \n",
    "df02['Total_FishProd'] = df02['SoftStringRingRibbon'] + df02['Fishing_BuoysAndFloats'] + df02['Fishing_Net'] + df02['FishingGlowSticks'] + df02['FishingLineLureRope'] + df02['FishingOtherPlasticDebris'] + df02['PlasticStraps']\n",
    "\n",
    "df02['Totales_Absolutos'] = df02['HardSoftPersonalCareProduc'] + df02['SoftCigaretteButts'] + df02['HardLighter'] + df02['SoftBag'] + df02['SoftSheets'] + df02['SoftWrapperOrLabel'] + df02['HardOtherPlasticBottle'] + df02['PlasticOrFoamFoodContainer'] + df02['HardPlasticBeverageBottle'] + df02['HardOrSoftPlasticBottleCap'] + df02['HardBucketOrCrate'] + df02['PlasticOrFoamPlatesBowlsCup'] + df02['HardSoftLollipopStickEarBu'] + df02['SoftStraw'] + df02['OtherPlasticDebris'] + df02['SoftOtherPlastic'] + df02['FoamOtherPlasticDebris'] + df02['OtherHardPlastic'] + df02['SoftStringRingRibbon'] + df02['Fishing_BuoysAndFloats'] + df02['Fishing_Net'] + df02['FishingGlowSticks'] + df02['FishingLineLureRope'] + df02['FishingOtherPlasticDebris'] + df02['PlasticStraps'] \n",
    "\n",
    "#### Aggregation Functions\n",
    "\n",
    "### Obteniendo la media agrupada por ShipName\n",
    "df_gr_1 = df.groupby('ShipeName')['Quantity'].mean()\n",
    "\n",
    "### Diferentes funciones de Agregacion median(), value_counts(normalize=True)\n",
    "df_gr_2 = df.groupby('ShipName')['Quantity'].agg([min, max, sum, np.mean])\n",
    "\n",
    "### Agrupando por 2 Variables ShipName & ShipperName y dif agregaciones\n",
    "df_gr_3 = df.groupby('ShipName, ShipperName')['Quantity'].agg([min, max, sum, np.mean])\n",
    "\n",
    "### Agrupando por 2 Variables e indicando el tipo de agregacion a cada variable\n",
    "df_gr_4 = df.groupby('ShipName, ShipperName')[['Quantity', 'UnitPrice']].agg({'Quantity':['sum'], 'UnitPrice':['mean']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94eb87c",
   "metadata": {},
   "source": [
    "### Drop Duplicate Values - df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d08aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup_1 = df.drop_duplicates(subset='ShipName')\n",
    "df_dup_2 = df.drop_duplicates(subset=['ShipName','Salesperson'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f780a4e",
   "metadata": {},
   "source": [
    "### Pivot Tables - df.pivot_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = df.pivot_table('SalesAmount', index='ShipCountry', columns='ShipperName',aggfunc=[np.sum])\n",
    "\n",
    "### Rellenando los vacios con 0 y agregando totales\n",
    "pivot_table = df.pivot('SalesAmount', index='ShipCountry',columns='ShipperName',aggfunc=[np.median, np.sum], fill_value=0, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae595a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54388 entries, 0 to 54387\n",
      "Data columns (total 40 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Record                       54388 non-null  int64  \n",
      " 1   Longitude                    54388 non-null  float64\n",
      " 2   Latitude                     54388 non-null  float64\n",
      " 3   Continent                    54388 non-null  object \n",
      " 4   Country                      54388 non-null  object \n",
      " 5   State                        54388 non-null  object \n",
      " 6   Adress                       54388 non-null  object \n",
      " 7   Year                         54388 non-null  int64  \n",
      " 8   HardPlasticBeverageBottle    54388 non-null  int64  \n",
      " 9   HardOtherPlasticBottle       54388 non-null  int64  \n",
      " 10  HardOrSoftPlasticBottleCap   54388 non-null  int64  \n",
      " 11  PlasticOrFoamFoodContainer   54388 non-null  float64\n",
      " 12  HardBucketOrCrate            54388 non-null  int64  \n",
      " 13  HardLighter                  54388 non-null  float64\n",
      " 14  OtherHardPlastic             54388 non-null  int64  \n",
      " 15  PlasticOrFoamPlatesBowlsCup  54388 non-null  int64  \n",
      " 16  HardSoftPersonalCareProduc   54388 non-null  int64  \n",
      " 17  HardSoftLollipopStickEarBu   54388 non-null  int64  \n",
      " 18  SoftBag                      54388 non-null  int64  \n",
      " 19  SoftWrapperOrLabel           54388 non-null  int64  \n",
      " 20  SoftStraw                    54388 non-null  float64\n",
      " 21  SoftOtherPlastic             54388 non-null  int64  \n",
      " 22  SoftCigaretteButts           54388 non-null  float64\n",
      " 23  SoftStringRingRibbon         54388 non-null  int64  \n",
      " 24  Fishing_Net                  54388 non-null  int64  \n",
      " 25  FishingLineLureRope          54388 non-null  int64  \n",
      " 26  Fishing_BuoysAndFloats       54388 non-null  int64  \n",
      " 27  FoamOtherPlasticDebris       54388 non-null  int64  \n",
      " 28  OtherPlasticDebris           54388 non-null  float64\n",
      " 29  SoftSheets                   54388 non-null  int64  \n",
      " 30  PlasticStraps                54388 non-null  int64  \n",
      " 31  FishingGlowSticks            54388 non-null  int64  \n",
      " 32  FishingOtherPlasticDebris    54388 non-null  int64  \n",
      " 33  Total_PCare                  54388 non-null  int64  \n",
      " 34  Total_CigLig                 54388 non-null  float64\n",
      " 35  Total_Bags                   54388 non-null  int64  \n",
      " 36  Total_HF_Plast               54388 non-null  float64\n",
      " 37  Total_PDebris                54388 non-null  float64\n",
      " 38  Total_FishProd               54388 non-null  int64  \n",
      " 39  Totales_Absolutos            54388 non-null  float64\n",
      "dtypes: float64(11), int64(25), object(4)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "####### Verify last action - Best practice\n",
    "df02.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77271d05",
   "metadata": {},
   "source": [
    "### Freezepanes - df.set_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = df.set_index('ShipName')\n",
    "df_01 = df.set_index(['ShipName','ShipperName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9cc8d4",
   "metadata": {},
   "source": [
    "### Selection Columns by Label  - df.loc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Select Columns (.LOC & .iLOC)\n",
    "# The loc function is used to select columns by names. As usual, the values before the coma stand for the rows and after refer to the column. We need to use the brackets to select more than one column.\n",
    "# The iloc is used for accessing the particular rows and columns by integer index.\n",
    "\n",
    "#### .LOC (Locate)\n",
    "# Filtering the Dataset based on labels\n",
    "# The following line is an example which filters the data from Row 00 until\n",
    "#  Row 02\n",
    "df_America.loc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49341388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Selection Columns by Label - df.loc\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\n",
    "df_02 = df_01.loc[['QUICK-Stop','Rancho grande']]\n",
    "df_07 = df.iloc[:,[0,1]]\n",
    "df_08 = df.iloc[1:100,[0,1]]\n",
    "df_09 = df.iloc[[100,200,300,400] , 0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb16b8",
   "metadata": {},
   "source": [
    "### Select Specific Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46083195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_03 = df.loc[:,['ShipName','ShipAddress']]\n",
    "df_04 = df_01.loc[['QUICK-Stop','Rancho grande'],['ShipAddress','ShipRegion']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48edb334",
   "metadata": {},
   "source": [
    "### Selection Columns by Position - df.iloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### .ILOC \n",
    "# There is another method to select multiple rows and columns in Pandas. \n",
    "# You can use iloc[]. This method uses the index instead of the columns name.\n",
    "# .Iloc allow us to select data based on the position\n",
    "df_America_loc02 = df_America.iloc[[100,200]]\n",
    "\n",
    "# Select Columns by Var & by Index\n",
    "df_America_loc03 = df_America.iloc[:,[0,1]]\n",
    "\n",
    "# Select by intersect and index\n",
    "# Obtain the first 100 rows from America DataSet, including Index plus\n",
    "# 2 Attributes\n",
    "df_America_loc04 = df_America.iloc[1:100,[0,1]]\n",
    "\n",
    "# # Obtain rows (100, 200, 300, 400)  from America DataSet,\n",
    "# including Index plus 4 columns (attributes)\n",
    "df_America_loc05 = df_America.iloc[[100,200,300,400] , 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1cd371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Selection Columns by Position\n",
    "df_05 = df.iloc[1:100] # TOP 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Select range - df.iloc\n",
    "df_06 = df.iloc[[100,200]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf9bb2",
   "metadata": {},
   "source": [
    "### Filter Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c414d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ProductID','CustomerID']] # Poner 2 SquareBrackets nos permite seguir ingresando mas columnas hacia la derecha\n",
    "df.loc[:,['ProductID', 'CustomerID']]\n",
    "result_2 = df[df['ProductID'] > 50] \n",
    "\n",
    "# Filtering using Logical Ops (and / or / not / isin)\n",
    "df_fil_3 = df[df['ShipName']=='LILA-Supermercado']\n",
    "df_fil_3 = df[(df['ShipName']=='LILA-Supermercado') & (df['ProductID']==30)]\n",
    "\n",
    "# isin # Nos permite realizar busquedas especificas\n",
    "df_fil_4 = df[df['ShipName'].isin(['LILA-Supermercado','Familia Arquibaldo'])]\n",
    "\n",
    "# np.logical_and // np.logical_or // np.logical_not # Customize your filters by rank\n",
    "df_fil_5 = df[np.logical_and(df['ProductID']>=50,df['ProductID']<=60)]\n",
    "df_fil_6 = df[np.logical_not(df['ProductID']>=50)]\n",
    "df_fil_7 = df[np.logical_not(df['ProductID']>=50)][['ShipName','ShipAddress']]\n",
    "df_fil_8 = df.loc[np.logical_not(df['ProductID']>=50),['ShipName','ShipAddress']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45985359",
   "metadata": {},
   "source": [
    "### Filter Top 10 (Discrete Objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro Analysis\n",
    "# Top 10\n",
    "# nlargest is a pandas method that returns the first n rows ordered by columns in descending order.\n",
    "plasticbottle01 = df02.nlargest(10,'HardPlasticBeverageBottle')\n",
    "plasticbottle02 = df02.nlargest(10,'HardOtherPlasticBottle')\n",
    "plasticbottle03 = df02.nlargest(10,'HardOrSoftPlasticBottleCap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bdd697",
   "metadata": {},
   "source": [
    "### Sort Values - df.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b00f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ordenando de forma ascendente\n",
    "sort1 = df.sort_values('ProductID')\n",
    "\n",
    "### Ordenando de forma descendente\n",
    "sort2 = df.sort_values('ProductID', ascending=False)\n",
    "\n",
    "### Ordenando por Multiples Columnas\n",
    "sort3 = df.sort_values(['ProductID', 'OrderID'])\n",
    "\n",
    "### Ordenando por multiples columnas y descendente y ascendente\n",
    "sort4 = df.sort_values(['ProductID', 'OrderID'], ascending=[False, True])\n",
    "sort4 = df.sort_values(['ProductID', 'OrderID'], ascending=[False, True])\n",
    "\n",
    "### Ordenando por el indice\n",
    "sort5 = df.set_index('ShipName').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eeb62f",
   "metadata": {},
   "source": [
    "### Gruop By - df[[]].groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e10d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by + with 1 condition\n",
    "df[['Gender','Exited']].groupby('Gender').mean()\n",
    "\n",
    "# Group by + 2 conditions\n",
    "df[['Gender','Exited']].groupby('Gender').agg(['mean','count'])\n",
    "\n",
    "# Group by 2 + 1 condition\n",
    "df[['Gender','Geography','Exited']].groupby(['Gender','Geography']).mean()\n",
    "\n",
    "# Group by 2 + Sort Asc\n",
    "df[['Gender','Geography','Exited']].groupby(['Gender','Geography']).mean()\n",
    ".sort_values(by='Exited')\n",
    "\n",
    "# Group by 2 + Sort Desc\n",
    "df[['Gender','Geography','Exited']].groupby(['Gender','Geography']).mean()\n",
    ".sort_values(by='Exited', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6d655",
   "metadata": {},
   "source": [
    "### If - Elif - Else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista1 = []\n",
    "\n",
    "for producto in df['Product ID']:\n",
    "    if producto >=50:\n",
    "        lista1.append(True)\n",
    "    else:\n",
    "        lista1.append(False)\n",
    "        \n",
    "len(lista1)\n",
    "        \n",
    "fil_1 = pd.Series(lista1)\n",
    "        \n",
    "df_new = df[fil_1]\n",
    "\n",
    "# ============================================================================\n",
    "# IF con una condiciion a cumplirse y un resultado para cuando no se cumple\n",
    "# ============================================================================\n",
    "\n",
    "x = 10\n",
    "\n",
    "### IF con una condicion\n",
    "\n",
    "if x <12:\n",
    "    print('10 es menor que 12')\n",
    "\n",
    "\n",
    "### IF con una condicion a cumplir y cuando no se cumple\n",
    "\n",
    "if x < 9:\n",
    "    print('10 es menor que 9')\n",
    "else:\n",
    "    print('10 no es menor que 12')\n",
    "    \n",
    "### IF anidado que evalue la cantidad de varuiables condicionales\n",
    "\n",
    "if x > 11 and x < 20:\n",
    "    print('10 es mayor que 11 y menor que 20')\n",
    "elif x > 5 or x < 9:\n",
    "    print('10 es mayor que 5 o menor que 9')\n",
    "else:\n",
    "    print('Nose cumple ningun criterio')\n",
    "    \n",
    "# Example_02\n",
    "\n",
    "lst = [4, 5, 6, 8, 10]\n",
    "i = 6\n",
    "\n",
    "if i in lst:\n",
    "\tprint(\"Yes 6 is present in the list\")\n",
    "else:\n",
    "\tprint(\"No 6 is not present in the list\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4270f2",
   "metadata": {},
   "source": [
    "### Bucles For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fef432",
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna, fila in df.iterrows():\n",
    "    df.loc[columna, 'ShipCityCopia'] = fila['ShipCity'].upper()\n",
    "    \n",
    "print(df.head())\n",
    "\n",
    "df['ShipCityCopia2'] = df['ShipCity'].apply(len)\n",
    "\n",
    "for columna, fila in df.iterrows():\n",
    "    df.loc[columna, 'ShipCityCopia'] = fila['ShipCity'].upper()\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df['ShipCityCopia2'] = df['ShipCity'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15900eb4",
   "metadata": {},
   "source": [
    "### Lists [ ]\n",
    "####### You use lists to store or organize data in a sequential order. \n",
    "####### This data can be a string, numbers, or iterables like a list.\n",
    "####### A list is also mutable, which means that it can expand and change after you declare it (you add new elements to it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_1 = [\"Dayana\", \"Juan\", \"Roger\", \"Antonio\"]\n",
    "Lista_2 = [\"Luis\", 90, \"Gerald\", 40, \"Anthony\", 30]\n",
    "\n",
    "#### Insert Values into a list (extend, insert, append)\n",
    "\n",
    "# Method 01 extend (Inserts multiple objects at the time)\n",
    "Lista_2.extend([\"Esteban\", 20])\n",
    "Lista_2\n",
    "# Method 02\n",
    "Lista_2 = Lista_2 + [\"Celeste\", 10]\n",
    "# Method 03 insert ((Inserts multiple objects at the time))\n",
    "Lista_2.insert(11, \"Hola\")\n",
    "print(Lista_2)\n",
    "# Method 04 append (Inserts 1 object at the time)\n",
    "Lista_2.append('Snowflake')\n",
    "print(Lista_2)\n",
    "\n",
    "#### Remove Values from a list (remove)\n",
    "\n",
    "Lista_2.remove(\"Hola\")\n",
    "print(Lista_2)\n",
    "\n",
    "#### Remove Values by Position (remove)\n",
    "# Elimina los 2 elementos q se encuentren anteriores al ultimo\n",
    "del(Lista_2[-2:])\n",
    "print(Lista_2)\n",
    "\n",
    "#### Position of an element within a list (index)\n",
    "\n",
    "print(Lista_2.index(\"Anthony\"))\n",
    "print(Lista_2[4:6])\n",
    "\n",
    "# The below exercise helps us to get an letter from an object in a list\n",
    "# 1st index is associated to an object\n",
    "# 2nd index refers to the \n",
    "favorites = ['raindrops', 'roses', 'whiskers', 'snowflakes']\n",
    "print(favorites[-2][-3])\n",
    "# Inversely if we need to get the last object\n",
    "# Note: Index [0] acts for the 1st object solely.\n",
    "favorites[-1]\n",
    "favorites[1]\n",
    "\n",
    "#### A List composed by multiple lists\n",
    "\n",
    "Lista_3 = [[\"Antonio\", 80], [\"Luis\", 90], [\"Gerald,40\"], [\"Esteban\", 20]]\n",
    "\n",
    "#### Number of items in a list(len.function)\n",
    "# The len() function returns the number of items in an object\n",
    "len(Lista_3)\n",
    "\n",
    "#### Adding Lists\n",
    "\n",
    "Morph_list = favorites + Lista_3\n",
    "\n",
    "#### Convert two lists into a Dictionary (zip, dict)\n",
    "\n",
    "name = [\"Dave\", \"Jerry\", \"Sasha\"]\n",
    "score = [43, 56, 78]\n",
    "result = zip(name, score)\n",
    "type(result)\n",
    "dict = dict(result)\n",
    "\n",
    "#### Add Index using the enumerate function\n",
    "\n",
    "l1 = [\"eat\", \"sleep\", \"repeat\"]\n",
    "s1 = \"geek\"\n",
    "# creating enumerate objects\n",
    "obj1 = enumerate(l1)\n",
    "obj2 = enumerate(s1)\n",
    "print (\"Return type:\", type(obj1))\n",
    "print (list(obj1))\n",
    "# changing start index to 2 from 0\n",
    "print (list(enumerate(s1, 2)))\n",
    "\n",
    "# Count the number of times the values in an iterable occurs (counter)\n",
    "from collections import Counter\n",
    "lst = [\"Free\", \"Code\", \"Camp\", \"Code\", \"Free\"]\n",
    "print(Counter(lst))\n",
    "\n",
    "\n",
    "#### LISTS\n",
    "\n",
    "#### LIST [ ] - Create\n",
    "# The following list is conformed by 5 Romanian institutions.\n",
    "# This specifi selection allow us to review contextual results and/or metrics.\n",
    "Romanian_list = [\"BANCA ROMANA PENTRU DEZVOLTARE\",\n",
    "          \"MINISTRY OF PUBLIC  FINANCE\",\n",
    "          \"BANCA ROMANA PENTRU DEZVOLTARE\",\n",
    "          \"TRANSELECTRICA S.A\",\n",
    "          \"TERMOELECTRICA S.A\"]\n",
    "# Print the list in order to verify the countries we are going to investigate.\n",
    "print(Romanian_list)\n",
    "# The following options allow us to consult the position in which a country is\n",
    "# stored within the list.\n",
    "print(Romanian_list[1])\n",
    "print(Romanian_list[-3])\n",
    "\n",
    "#### LIST - Append (Add)\n",
    "# Sometimes we need to expand our range of study, in that way we can use the \n",
    "# command append to include a new country within our list, for future querys.\n",
    "\n",
    "Romanian_list.append(\"NUOVO AMANECER ROMANO\")\n",
    "# Lets verify if this recent was stored succesfully.\n",
    "print(Romanian_list)\n",
    "\n",
    "#### LIST - Insert\n",
    "# Insert a category into an specific position within the list.\n",
    "Romanian_list.insert(2,\"GRATIA OMNIPOTENTIS\")\n",
    "print(Romanian_list)\n",
    "\n",
    "#### LIST - Extend\n",
    "# Insert multiple categories\n",
    "Romanian_list.extend([\"IMPERIO_ROMANO_01\", \"IMPERIO_ROMANO_02\", \"IMPERIO_ROMANO_03\"])\n",
    "print(Romanian_list)\n",
    "\n",
    "#### LIST - Index\n",
    "# Index provides the exact position of a category within the list.\n",
    "print(Romanian_list.index(\"IMPERIO_ROMANO_02\"))\n",
    "\n",
    "#### LIST - In\n",
    "# From time to time we shall need to consult if a category is located within \n",
    "# an specific list. In order to accomplish that we shouls use the command In.\n",
    "# Lets the results of the following 2 querys:\n",
    "print(\"NUOVO AMANECER ROMANO\" in Romanian_list)\n",
    "print(\"ARCADIA\" in Romanian_list)\n",
    "\n",
    "#### LIST - Remove\n",
    "# Often we must delete categories derived from business affairs or perhaps the \n",
    "# Headquarters decides to unify varios categories into one unique cluster.\n",
    "# For those cases we can take advantage of the following command:\n",
    "Romanian_list.remove(\"IMPERIO_ROMANO_01\")\n",
    "print(Romanian_list)\n",
    "\n",
    "#### LIST - POP\n",
    "# The instruction Pop allow us to eliminate categories from the last position\n",
    "# until the first position, one by one.\n",
    "# So the following actions permit us to delete all those records wee dont need\n",
    "# anymore and set the list conform with the original categories that came from\n",
    "# the rawdata.\n",
    "\n",
    "Romanian_list.pop()\n",
    "print(Romanian_list)\n",
    "Romanian_list.pop()\n",
    "print(Romanian_list)\n",
    "Romanian_list.pop()\n",
    "print(Romanian_list)\n",
    "\n",
    "Romanian_list.remove(\"BANCA ROMANA PENTRU DEZVOLTARE\")\n",
    "print(Romanian_list)\n",
    "\n",
    "Romanian_list.remove(\"GRATIA OMNIPOTENTIS\")\n",
    "print(Romanian_list)\n",
    "\n",
    "#### LIST - Concatenate\n",
    "# Sometimes we need to melt 2 Regions into 1 new Region/GeoCluster\n",
    "# We can use the following code to transform 2 regions into an unique \n",
    "# Geo_Cluster.\n",
    "\n",
    "Serbia_list = [\"PRESIDENT, MONTENEGRO BANKA DD\",\n",
    "               \"NAFTAGAS KOMBINAT NAFTNE IND\"\n",
    "               ]\n",
    "Serbia_list\n",
    "EuroCluster = Romanian_list + Serbia_list\n",
    "print(EuroCluster)\n",
    "\n",
    "#### LIST - multiply\n",
    "## Multiply the list on its own by 3 times.\n",
    "\n",
    "Triple_EuroCluster = EuroCluster * 3\n",
    "print(Triple_EuroCluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf2788",
   "metadata": {},
   "source": [
    "### Tuples ( )\n",
    "####### A tuple is another data collection type in Python. \n",
    "####### You also use it to store and organize data in the form of a list.\n",
    "####### The only difference is that it is immutable, which means it cannot expand (you can't add new elements to it) like a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tupla_1 = (\"Gerald\", 40, \"Marlon\", 20, \"Luis\", 10)\n",
    "Tupla_2 = ((\"Gerald\", 40), (\"Marlon\", 20), (\"Luis\", 10))\n",
    "\n",
    "#### Position of an element within a Tuple []\n",
    "\n",
    "Tupla_1[1]\n",
    "\n",
    "Tupla_2[1]\n",
    "\n",
    "#### Convert a Tuple into a List\n",
    "\n",
    "lista_4 = list(Tupla_1)\n",
    "type(lista_4)\n",
    "\n",
    "Tupla_3 = tuple(lista_4)\n",
    "type(Tupla_3)\n",
    "\n",
    "#### Consult an object within a tuple (by Name)\n",
    "\n",
    "print(\"Gerald\" in Tupla_1)\n",
    "\n",
    "#### Qty of values in a Tuple (len)\n",
    "\n",
    "print(len(Tupla_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8aeda",
   "metadata": {},
   "source": [
    "### Dictionaries { }\n",
    "####### A dictionary is a Python collection that stores data as key-value pairs.\n",
    "####### You can create a dictionary using curly braces. Also dictionaries are mutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7141d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estudiantes = {\"Juan\": \"Python\", \"Luis Diego\": \"RStudio\", \"Roger\": \"SQL\"}\n",
    "type(estudiantes)\n",
    "\n",
    "#### Consult Dictionary Keys (keys)\n",
    "\n",
    "estudiantes.keys()\n",
    "\n",
    "#### Consult Pair_Values associated to a Key\n",
    "\n",
    "estudiantes[\"Juan\"]\n",
    "\n",
    "#### Add New Key_Value_Pairs\n",
    "\n",
    "estudiantes[\"Esteban\"] = \"Julia\"\n",
    "\n",
    "del estudiantes[\"Esteban\"]\n",
    "\n",
    "#### # A Dictionary made by multiple dictionaries\n",
    "\n",
    "equipo = {\"Dayana\": {\"Curso\": \"RPA\", \"Nota\": 90},\n",
    "          \"Gerald\": {\"Curso\": \"R\", \"Nota\": 100}}\n",
    "\n",
    "#### # Add a Dictionary into a Dictionary\n",
    "\n",
    "equipo[\"Esteban\"] = {\"Curso\": \"Python\", \"Nota\": 80}\n",
    "\n",
    "print(equipo)\n",
    "\n",
    "\n",
    "#### DICTIONARIES\n",
    "# We can also think of a DataFrame as a specialization of a dictionary. Where\n",
    "# a dictionary maps a key to a value, a DataFrame maps a column name to a\n",
    "# series of column data. (Python Data Science Handbook, Ed. 2006, pg 103)\n",
    "\n",
    "American_nations = {1: \"Guatemala\",\n",
    "                    2: \"Mexico\",\n",
    "                    3: \"Peru\",\n",
    "                    4: \"Uruguay\",\n",
    "                    5: \"Venezuela\"\n",
    "                    }\n",
    "\n",
    "Rest_of_the_world = {1: \"Romania\",\n",
    "                     2: \"Russain Federation\",\n",
    "                     3: \"Serbia\",\n",
    "                     4: \"Turkia\",\n",
    "                     5: \"Ukraine\"\n",
    "                     }\n",
    "\n",
    "#### PPRINT\n",
    "# The command Pprint executes vertical result on the console pane, in that way\n",
    "# we can observe results in a more clear and sorted way.\n",
    "pprint.pprint(American_nations, width=-1)\n",
    "pprint.pprint(Rest_of_the_world, width=-1)\n",
    "\n",
    "#### DICTIONARY - { } - Create\n",
    "# Similarly to lists, dictionaries is a powerful customization tool that allow\n",
    "# us to sort groups of data within a cluster/label.\n",
    "America_portfolio = {\"Mexico\": \"DF\", \"Guatemala\":\"Peten\", \"Venezuela\":\"Bolivar\", \"Peru\":\"Arequipa\"}\n",
    "print(America_portfolio)\n",
    "\n",
    "# 02 Additional method about how to create a Dictionary\n",
    "\n",
    "keys = [\"Russian Federation\", \"Serbia\", \"Turkey\"]\n",
    "values = [\"Leningrado\", \"Belgrado\", \"Estambul\"]\n",
    "Euro_portfolio = dict((zip(keys,values)))\n",
    "Euro_portfolio\n",
    "\n",
    "#### DICTIONARY - Add\n",
    "# I almost forgot to include a pair of countries within the Euro dictionary\n",
    "Euro_portfolio[\"Romania\"]=\"Bucarest\"\n",
    "Euro_portfolio[\"Ukraine\"]=\"Kiev\"\n",
    "Euro_portfolio\n",
    "\n",
    "#### DICTIONARY - Mod\n",
    "Euro_portfolio[\"Ukraine\"]=\"Odesa\"\n",
    "Euro_portfolio\n",
    "\n",
    "#### DICTIONARY - Delete\n",
    "# Delete a wrong record.\n",
    "del Euro_portfolio[\"Ukraine\"]\n",
    "Euro_portfolio\n",
    "\n",
    "#### DICTIONARY - Keys\n",
    "# Check the Dictionary´s keys.\n",
    "Euro_portfolio.keys()\n",
    "\n",
    "#### DICTIONARY - Examples\n",
    "\n",
    "# Example_01:\n",
    "    \n",
    "def show_info_about_item(chosen_item=\"phone\"):\n",
    "  info_dict = {\n",
    "    \"phone\": \"Handheld communication device\",\n",
    "    \"car\": \"Self-propelled ground vehicle\",\n",
    "    \"dinosaur\": \"Extinct lizard\"\n",
    "  }\n",
    "  \n",
    "  return info_dict.get(chosen_item, \"No info available\")\n",
    "\n",
    "# Example_02:\n",
    "    \n",
    "def add_one(x):\n",
    "  return x + 1\n",
    "\n",
    "def divide_by_two(x):\n",
    "  return x/2\n",
    "\n",
    "def square(x):\n",
    "  return x**2\n",
    "\n",
    "def invalid_op(x):\n",
    "  raise Exception(\"Invalid operation\")\n",
    "\n",
    "# The better way:\n",
    "def perform_operation(x, chosen_operation=\"add_one\"):\n",
    "  ops = {\n",
    "    \"add_one\": add_one,\n",
    "    \"divide_by_two\": divide_by_two,\n",
    "    \"square\": square\n",
    "  }\n",
    "  \n",
    "  chosen_operation_function = ops.get(chosen_operation, invalid_op)\n",
    "  \n",
    "  return chosen_operation_function(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea657ab",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "####### There are 3 types of Funcions: \n",
    "#######    Functions with No Arguments\n",
    "#######    Functions with One-Single Argument\n",
    "#######    Functions with Multiple Arguments.\n",
    "####### Resources: https://www.kaggle.com/code/alexisbcook/functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c2131",
   "metadata": {},
   "source": [
    "#### Functions with No Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function with no arguments and with no return\n",
    "def print_hello():\n",
    "    print(\"Hello, you!\")\n",
    "    print(\"Good morning!\")\n",
    "    \n",
    "# Call the function\n",
    "print_hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d97600",
   "metadata": {},
   "source": [
    "#### Functions with One-Single Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ef917",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE_01 \n",
    "    \n",
    "# Step_02: Define the function\n",
    "# The add_three() function below accepts any number, adds three to it, and then returns the result.\n",
    "def add_three(input_var): # input_var  is a <single_argument>\n",
    "    output_var = input_var + 3\n",
    "    return output_var   \n",
    "\n",
    "# Step_03: Run the function with 10 as input\n",
    "new_number = add_three(10)\n",
    "# Check that the value is 13, as expected\n",
    "print(new_number)  \n",
    "\n",
    "### EXAMPLE_02 \n",
    "\n",
    "# Calculate a weekly paycheck after taxes.\n",
    "# They're in a 12% tax bracket (in other words, 12% of their salary is taken for taxes, and they only take home 88%), and\n",
    "# They're paid hourly, at a rate of $15/hour.\n",
    "def get_pay(num_hours):\n",
    "    # Pre-tax pay, based on receiving $15/hour\n",
    "    pay_pretax = num_hours * 15\n",
    "    # After-tax pay, based on being in 12% tax bracket\n",
    "    pay_aftertax = pay_pretax * (1 - .12)\n",
    "    return pay_aftertax\n",
    "\n",
    "# Calculate pay based on working 40 hours\n",
    "pay_fulltime = get_pay(40)\n",
    "print(pay_fulltime)\n",
    "\n",
    "### EXAMPLE_03 \n",
    "\n",
    "def evaluate_temp(temp):\n",
    "    # Set an initial message\n",
    "    message = \"Normal temperature.\"\n",
    "    # Update value of message only if temperature greater than 38\n",
    "    if temp > 38:\n",
    "        message = \"Fever!\"\n",
    "    return message\n",
    "\n",
    "print(evaluate_temp(37))\n",
    "print(evaluate_temp(39))\n",
    "\n",
    "### EXAMPLE_04 \n",
    "\n",
    "def evaluate_temp_with_else(temp):\n",
    "    if temp > 38:\n",
    "        message = \"Fever!\"\n",
    "    else:\n",
    "        message = \"Normal temperature.\"\n",
    "    return message\n",
    "\n",
    "print(evaluate_temp_with_else(37))\n",
    "\n",
    "### EXAMPLE_05 \n",
    "\n",
    "def evaluate_temp_with_elif(temp):\n",
    "    if temp > 38:\n",
    "        message = \"Fever!\"\n",
    "    elif temp > 35:\n",
    "        message = \"Normal temperature.\"\n",
    "    else:\n",
    "        message = \"Low temperature.\"\n",
    "    return message\n",
    "\n",
    "evaluate_temp_with_elif(36)\n",
    "\n",
    "### EXAMPLE_06 \n",
    "\n",
    "def get_taxes(earnings):\n",
    "    if earnings < 12000:\n",
    "        tax_owed = .25 * earnings\n",
    "    else:\n",
    "        tax_owed = .30 * earnings\n",
    "    return tax_owed\n",
    "\n",
    "ana_taxes = get_taxes(9000)\n",
    "bob_taxes = get_taxes(15000)\n",
    "\n",
    "print(ana_taxes)\n",
    "print(bob_taxes)\n",
    "\n",
    "### EXAMPLE_07 \n",
    "\n",
    "def get_dose(weight):\n",
    "    # Dosage is 1.25 ml for anyone under 5.2 kg\n",
    "    if weight < 5.2:\n",
    "        dose = 1.25\n",
    "    elif weight < 7.9:\n",
    "        dose = 2.5\n",
    "    elif weight < 10.4:\n",
    "        dose = 3.75\n",
    "    elif weight < 15.9:\n",
    "        dose = 5\n",
    "    elif weight < 21.2:\n",
    "        dose = 7.5\n",
    "    # Dosage is 10 ml for anyone 21.2 kg or over\n",
    "    else:\n",
    "        dose = 10\n",
    "    return dose\n",
    "\n",
    "print(get_dose(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0581b1d",
   "metadata": {},
   "source": [
    "#### Functions with Multiple Arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd42074",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE_01\n",
    "\n",
    "# get_pay_with_more_inputs() function below, which calculates a weekly paycheck based on three arguments:\n",
    "# num_hours - number of hours worked in one week\n",
    "# hourly_wage - the hourly wage (in $/hour)\n",
    "# tax_bracket - percentage of your salary that is removed for taxes\n",
    "\n",
    "def get_pay_with_more_inputs(num_hours, hourly_wage, tax_bracket):\n",
    "    # Pre-tax pay\n",
    "    pay_pretax = num_hours * hourly_wage\n",
    "    # After-tax pay\n",
    "    pay_aftertax = pay_pretax * (1 - tax_bracket)\n",
    "    return pay_aftertax\n",
    "\n",
    "higher_pay_aftertax = get_pay_with_more_inputs(40, 24, .22)\n",
    "print(higher_pay_aftertax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21198c6d",
   "metadata": {},
   "source": [
    "### Loops\n",
    "####### Loops: A loop is a piece of code that runs over and over again until the condition is false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tuple = (2, 3, 4, 6, 10, 12)\n",
    "my_new_lst = []\n",
    "for i in my_tuple:\n",
    "    if i % 3 == 0:\n",
    "        my_new_lst.append(i)\n",
    "print(my_new_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a8d41d",
   "metadata": {},
   "source": [
    "### Append - df.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dedfb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r('C:\\Users\\Asus VivoBook\\Dropbox\\My PC (DESKTOP-GN5CQHE)\\Documents\\My Studies\\PowerUp Institute\\Python\\week 01\\Tiendas\\vta_2014.csv')\n",
    "path = r('C:\\Users\\Asus VivoBook\\Dropbox\\My PC (DESKTOP-GN5CQHE)\\Documents\\My Studies\\PowerUp Institute\\Python\\week 01\\Tiendas\\vta_2013.csv')\n",
    "ap1 = pd.read_csv(path1,sep=',',header=0,index_col=False,encoding='Latin-1',engine='python')\n",
    "ap2 = pd.read_csv(path2,sep=',',header=0,index_col=False,encoding='Latin-1',engine='python')\n",
    "\n",
    "### Append anexa de forma vertical y deja valores repetidos\n",
    "ap3 = ap1.append(ap2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0dfdd2",
   "metadata": {},
   "source": [
    "### Concatenate  - pd.concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concatenar al nivel de la fila\n",
    "ap4 = pd.concat([ap1,ap2],ignore_index=True, axis=0)\n",
    "\n",
    "### concatenar a nivel de columna\n",
    "ap5 = pd.concat([ap1,ap2],ignore_index=True, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa06a740",
   "metadata": {},
   "source": [
    "### Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24de530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "#### JOIN - MERGE\n",
    "# =============================================================\n",
    "\n",
    "path3 = r'C:\\Users\\Asus VivoBook\\Dropbox\\My PC (DESKTOP-GN5CQHE)\\Documents\\My Studies\\PowerUp Institute\\Python\\week 01\\Tiendas\\vta_2014.csv')\n",
    "Precios = pd.ExcelFile(path3).parse(sheet_name='Precios',header=0,index_col=[0,1])\n",
    "Existencias = pd.ExcelFile(path3).parse(sheet_name='Existencias',header=0,index_col=[0,1])\n",
    "Catalogo = pd.ExcelFile(path3).parse(sheet_name='Catalogo',header=0,index_col=[0,1])\n",
    "\n",
    "# ============================================================\n",
    "# JOIN -- MERGE\n",
    "# ============================================================\n",
    "path = r'C:\\Users\\Asus VivoBook\\Dropbox\\My PC (DESKTOP-GN5CQHE)\\Documents\\My Studies\\PowerUp Institute\\Python\\week 04\\Combinar Consultas.csv')\n",
    "Existencias = pd.ExcelFile(path3).parse(sheet_name='Existencias',header=0,index_col=[0,1])\n",
    "Catalogo = pd.ExcelFile(path3)\n",
    "\n",
    "########## UNIENDO POR UNA COLUMNA\n",
    "\n",
    "Inner1 = pd.merge(Existencias,Precios,on = 'Codigo')\n",
    "\n",
    "########## UNIENDO POR UNA LLAVE EN LAS COLUMNAS (2 O mas)\n",
    "\n",
    "iNNER2 = pd.merge(Existencias,Precios,on = 'Codigo','Descripcion')\n",
    "\n",
    "########## UNIENDO LAS COLUMNAS SI SE LLAMARN DIFERENTES\n",
    "\n",
    "Inner3 = pd.merge(Existencias,Precios,\n",
    "                  left_on='Codigo',\n",
    "                  right_on='Codigo')\n",
    "\n",
    "#### LEFT JOIN\n",
    "\n",
    "Left1 = pd.merge(Existencias,Precios,\n",
    "                  left_on='Codigo',\n",
    "                  right_on='Codigo'\n",
    "                 how='left').reset_index()\n",
    "\n",
    "\n",
    "#### RIGHT JOIN\n",
    "\n",
    "Right1 = pd.merge(Existencias,Precios,\n",
    "                  left_on='Codigo',\n",
    "                  right_on='Codigo'\n",
    "                 how='right')\n",
    "                 \n",
    "#### FULL OUTER JOIN \n",
    "Outer11 = pd.merge(Existencias,Precios,\n",
    "                  left_on='Codigo',\n",
    "                  right_on='Codigo'\n",
    "                 how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b624ef",
   "metadata": {},
   "source": [
    "### Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dcf9d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total_PCare</th>\n",
       "      <th>Total_CigLig</th>\n",
       "      <th>Total_Bags</th>\n",
       "      <th>Total_HF_Plast</th>\n",
       "      <th>Total_PDebris</th>\n",
       "      <th>Total_FishProd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47537</th>\n",
       "      <td>119.98110</td>\n",
       "      <td>15.32586</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Zambales</td>\n",
       "      <td>2018</td>\n",
       "      <td>43074</td>\n",
       "      <td>107413.0</td>\n",
       "      <td>571492</td>\n",
       "      <td>621716.0</td>\n",
       "      <td>236213.0</td>\n",
       "      <td>32919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41879</th>\n",
       "      <td>119.90968</td>\n",
       "      <td>15.76393</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Zambales</td>\n",
       "      <td>2018</td>\n",
       "      <td>40815</td>\n",
       "      <td>91363.0</td>\n",
       "      <td>525644</td>\n",
       "      <td>575261.0</td>\n",
       "      <td>246275.0</td>\n",
       "      <td>31751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43440</th>\n",
       "      <td>120.98112</td>\n",
       "      <td>14.57938</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>National Capital Region</td>\n",
       "      <td>2018</td>\n",
       "      <td>37500</td>\n",
       "      <td>22680.0</td>\n",
       "      <td>297860</td>\n",
       "      <td>29496.0</td>\n",
       "      <td>7560.0</td>\n",
       "      <td>11606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47519</th>\n",
       "      <td>120.98120</td>\n",
       "      <td>14.57202</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>National Capital Region</td>\n",
       "      <td>2018</td>\n",
       "      <td>26155</td>\n",
       "      <td>20756.0</td>\n",
       "      <td>234609</td>\n",
       "      <td>197791.0</td>\n",
       "      <td>173515.0</td>\n",
       "      <td>31382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11413</th>\n",
       "      <td>0.01915</td>\n",
       "      <td>5.64315</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Greater Accra</td>\n",
       "      <td>2016</td>\n",
       "      <td>25124</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>202483</td>\n",
       "      <td>711736.0</td>\n",
       "      <td>41091.0</td>\n",
       "      <td>7516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42857</th>\n",
       "      <td>34.40541</td>\n",
       "      <td>-13.70671</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Malawi</td>\n",
       "      <td>Salima</td>\n",
       "      <td>2018</td>\n",
       "      <td>17255</td>\n",
       "      <td>8020.0</td>\n",
       "      <td>53148</td>\n",
       "      <td>57230.0</td>\n",
       "      <td>14919.0</td>\n",
       "      <td>12459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51253</th>\n",
       "      <td>-80.88443</td>\n",
       "      <td>-2.20830</td>\n",
       "      <td>South America</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>2018</td>\n",
       "      <td>16758</td>\n",
       "      <td>48850.0</td>\n",
       "      <td>156794</td>\n",
       "      <td>307610.0</td>\n",
       "      <td>107055.0</td>\n",
       "      <td>17697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40910</th>\n",
       "      <td>34.84820</td>\n",
       "      <td>-14.01708</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Malawi</td>\n",
       "      <td>Mangochi</td>\n",
       "      <td>2018</td>\n",
       "      <td>16420</td>\n",
       "      <td>4378.0</td>\n",
       "      <td>9502</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23063</th>\n",
       "      <td>-0.09544</td>\n",
       "      <td>5.58214</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Greater Accra</td>\n",
       "      <td>2017</td>\n",
       "      <td>13984</td>\n",
       "      <td>37128.0</td>\n",
       "      <td>110521</td>\n",
       "      <td>488155.0</td>\n",
       "      <td>23086.0</td>\n",
       "      <td>3241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28938</th>\n",
       "      <td>120.81721</td>\n",
       "      <td>14.28012</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Cavite</td>\n",
       "      <td>2017</td>\n",
       "      <td>13212</td>\n",
       "      <td>23596.0</td>\n",
       "      <td>107853</td>\n",
       "      <td>107855.0</td>\n",
       "      <td>71610.0</td>\n",
       "      <td>7929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Longitude  Latitude      Continent      Country  \\\n",
       "47537  119.98110  15.32586           Asia  Philippines   \n",
       "41879  119.90968  15.76393           Asia  Philippines   \n",
       "43440  120.98112  14.57938           Asia  Philippines   \n",
       "47519  120.98120  14.57202           Asia  Philippines   \n",
       "11413    0.01915   5.64315         Africa        Ghana   \n",
       "42857   34.40541 -13.70671         Africa       Malawi   \n",
       "51253  -80.88443  -2.20830  South America      Ecuador   \n",
       "40910   34.84820 -14.01708         Africa       Malawi   \n",
       "23063   -0.09544   5.58214         Africa        Ghana   \n",
       "28938  120.81721  14.28012           Asia  Philippines   \n",
       "\n",
       "                         State  Year  Total_PCare  Total_CigLig  Total_Bags  \\\n",
       "47537                 Zambales  2018        43074      107413.0      571492   \n",
       "41879                 Zambales  2018        40815       91363.0      525644   \n",
       "43440  National Capital Region  2018        37500       22680.0      297860   \n",
       "47519  National Capital Region  2018        26155       20756.0      234609   \n",
       "11413            Greater Accra  2016        25124       32067.0      202483   \n",
       "42857                   Salima  2018        17255        8020.0       53148   \n",
       "51253              Santa Elena  2018        16758       48850.0      156794   \n",
       "40910                 Mangochi  2018        16420        4378.0        9502   \n",
       "23063            Greater Accra  2017        13984       37128.0      110521   \n",
       "28938                   Cavite  2017        13212       23596.0      107853   \n",
       "\n",
       "       Total_HF_Plast  Total_PDebris  Total_FishProd  \n",
       "47537        621716.0       236213.0           32919  \n",
       "41879        575261.0       246275.0           31751  \n",
       "43440         29496.0         7560.0           11606  \n",
       "47519        197791.0       173515.0           31382  \n",
       "11413        711736.0        41091.0            7516  \n",
       "42857         57230.0        14919.0           12459  \n",
       "51253        307610.0       107055.0           17697  \n",
       "40910          2400.0         1729.0            2861  \n",
       "23063        488155.0        23086.0            3241  \n",
       "28938        107855.0        71610.0            7929  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Macro Analysis_01\n",
    "# Subsets_TOTALES BY CATEGORIES\n",
    "# Sort DESC\n",
    "Subset_TOTALS = df02[['Longitude','Latitude','Continent','Country','State','Year','Total_PCare', 'Total_CigLig', 'Total_Bags', 'Total_HF_Plast', 'Total_PDebris', 'Total_FishProd']]\n",
    "dfsortedbyTOTALS = Subset_TOTALS.sort_values(['Total_PCare', 'Total_CigLig', 'Total_Bags', 'Total_HF_Plast', 'Total_PDebris', 'Total_FishProd'],ascending=False)\n",
    "dfsortedbyTOTALS.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "868dbdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Totales_Absolutos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50184</th>\n",
       "      <td>-0.18886</td>\n",
       "      <td>5.61601</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Greater Accra</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>26420613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50190</th>\n",
       "      <td>0.89120</td>\n",
       "      <td>5.78178</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Volta</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>11188848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50182</th>\n",
       "      <td>-0.22500</td>\n",
       "      <td>5.52906</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Greater Accra</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>6915964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50181</th>\n",
       "      <td>-0.09813</td>\n",
       "      <td>5.57944</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Greater Accra</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>6876445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50185</th>\n",
       "      <td>0.76960</td>\n",
       "      <td>5.77169</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Volta</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>4298362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50188</th>\n",
       "      <td>-1.98369</td>\n",
       "      <td>10.88397</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Upper West</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>3804013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50186</th>\n",
       "      <td>0.73716</td>\n",
       "      <td>5.77198</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Volta</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>3104601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50180</th>\n",
       "      <td>0.01925</td>\n",
       "      <td>5.64319</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Greater Accra</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>1972616.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50187</th>\n",
       "      <td>0.68846</td>\n",
       "      <td>5.88012</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Volta</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>1730375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47537</th>\n",
       "      <td>119.98110</td>\n",
       "      <td>15.32586</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Zambales</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>1612827.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Longitude  Latitude Continent      Country          State  Year  Month  \\\n",
       "50184   -0.18886   5.61601    Africa        Ghana  Greater Accra  2018      9   \n",
       "50190    0.89120   5.78178    Africa        Ghana          Volta  2018      9   \n",
       "50182   -0.22500   5.52906    Africa        Ghana  Greater Accra  2018      9   \n",
       "50181   -0.09813   5.57944    Africa        Ghana  Greater Accra  2018      9   \n",
       "50185    0.76960   5.77169    Africa        Ghana          Volta  2018      9   \n",
       "50188   -1.98369  10.88397    Africa        Ghana     Upper West  2018      9   \n",
       "50186    0.73716   5.77198    Africa        Ghana          Volta  2018      9   \n",
       "50180    0.01925   5.64319    Africa        Ghana  Greater Accra  2018      9   \n",
       "50187    0.68846   5.88012    Africa        Ghana          Volta  2018      9   \n",
       "47537  119.98110  15.32586      Asia  Philippines       Zambales  2018      9   \n",
       "\n",
       "       Totales_Absolutos  \n",
       "50184         26420613.0  \n",
       "50190         11188848.0  \n",
       "50182          6915964.0  \n",
       "50181          6876445.0  \n",
       "50185          4298362.0  \n",
       "50188          3804013.0  \n",
       "50186          3104601.0  \n",
       "50180          1972616.0  \n",
       "50187          1730375.0  \n",
       "47537          1612827.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Macro Analysis_02\n",
    "# Subsets_ABSOLUTE TOTALS\n",
    "Subset_Absolute_Totals = df02[['Longitude','Latitude','Continent','Country','State','Year','Month','Totales_Absolutos']]\n",
    "dfsortedbyAbsolute_Totales = Subset_Absolute_Totals.sort_values(['Totales_Absolutos'],ascending=False)\n",
    "dfsortedbyAbsolute_Totales.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c72be0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Total_PCare</th>\n",
       "      <th>Total_CigLig</th>\n",
       "      <th>Total_Bags</th>\n",
       "      <th>Total_HF_Plast</th>\n",
       "      <th>Total_PDebris</th>\n",
       "      <th>Total_FishProd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Continent</th>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Asia</th>\n",
       "      <th>2018</th>\n",
       "      <td>119.98110</td>\n",
       "      <td>15.32586</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Zambales</td>\n",
       "      <td>43074</td>\n",
       "      <td>107413.0</td>\n",
       "      <td>571492</td>\n",
       "      <td>621716.0</td>\n",
       "      <td>236213.0</td>\n",
       "      <td>32919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>119.90968</td>\n",
       "      <td>15.76393</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Zambales</td>\n",
       "      <td>40815</td>\n",
       "      <td>91363.0</td>\n",
       "      <td>525644</td>\n",
       "      <td>575261.0</td>\n",
       "      <td>246275.0</td>\n",
       "      <td>31751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>120.98112</td>\n",
       "      <td>14.57938</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>National Capital Region</td>\n",
       "      <td>37500</td>\n",
       "      <td>22680.0</td>\n",
       "      <td>297860</td>\n",
       "      <td>29496.0</td>\n",
       "      <td>7560.0</td>\n",
       "      <td>11606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>120.98120</td>\n",
       "      <td>14.57202</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>National Capital Region</td>\n",
       "      <td>26155</td>\n",
       "      <td>20756.0</td>\n",
       "      <td>234609</td>\n",
       "      <td>197791.0</td>\n",
       "      <td>173515.0</td>\n",
       "      <td>31382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Africa</th>\n",
       "      <th>2016</th>\n",
       "      <td>0.01915</td>\n",
       "      <td>5.64315</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Greater Accra</td>\n",
       "      <td>25124</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>202483</td>\n",
       "      <td>711736.0</td>\n",
       "      <td>41091.0</td>\n",
       "      <td>7516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Asia</th>\n",
       "      <th>2018</th>\n",
       "      <td>102.13667</td>\n",
       "      <td>2.27628</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Melaka</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>102.13667</td>\n",
       "      <td>2.27628</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Melaka</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">North America</th>\n",
       "      <th>2018</th>\n",
       "      <td>-76.96442</td>\n",
       "      <td>38.89483</td>\n",
       "      <td>United States</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>-76.96442</td>\n",
       "      <td>38.89483</td>\n",
       "      <td>United States</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>-79.03804</td>\n",
       "      <td>35.75197</td>\n",
       "      <td>United States</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54388 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Longitude  Latitude        Country  \\\n",
       "Continent     Year                                       \n",
       "Asia          2018  119.98110  15.32586    Philippines   \n",
       "              2018  119.90968  15.76393    Philippines   \n",
       "              2018  120.98112  14.57938    Philippines   \n",
       "              2018  120.98120  14.57202    Philippines   \n",
       "Africa        2016    0.01915   5.64315          Ghana   \n",
       "...                       ...       ...            ...   \n",
       "Asia          2018  102.13667   2.27628       Malaysia   \n",
       "              2018  102.13667   2.27628       Malaysia   \n",
       "North America 2018  -76.96442  38.89483  United States   \n",
       "              2018  -76.96442  38.89483  United States   \n",
       "              2018  -79.03804  35.75197  United States   \n",
       "\n",
       "                                      State  Total_PCare  Total_CigLig  \\\n",
       "Continent     Year                                                       \n",
       "Asia          2018                 Zambales        43074      107413.0   \n",
       "              2018                 Zambales        40815       91363.0   \n",
       "              2018  National Capital Region        37500       22680.0   \n",
       "              2018  National Capital Region        26155       20756.0   \n",
       "Africa        2016            Greater Accra        25124       32067.0   \n",
       "...                                     ...          ...           ...   \n",
       "Asia          2018                   Melaka            0           0.0   \n",
       "              2018                   Melaka            0           0.0   \n",
       "North America 2018     District of Columbia            0           0.0   \n",
       "              2018     District of Columbia            0           0.0   \n",
       "              2018           North Carolina            0           0.0   \n",
       "\n",
       "                    Total_Bags  Total_HF_Plast  Total_PDebris  Total_FishProd  \n",
       "Continent     Year                                                             \n",
       "Asia          2018      571492        621716.0       236213.0           32919  \n",
       "              2018      525644        575261.0       246275.0           31751  \n",
       "              2018      297860         29496.0         7560.0           11606  \n",
       "              2018      234609        197791.0       173515.0           31382  \n",
       "Africa        2016      202483        711736.0        41091.0            7516  \n",
       "...                        ...             ...            ...             ...  \n",
       "Asia          2018           0             0.0            0.0               0  \n",
       "              2018           0             0.0            0.0               0  \n",
       "North America 2018           0             0.0            0.0               0  \n",
       "              2018           0             0.0            0.0               0  \n",
       "              2018           0             0.0            0.0               0  \n",
       "\n",
       "[54388 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Macro Analysis 03\n",
    "# Filter by Continent and Year\n",
    "dfTOTALS_filtered_Continent_YY = dfsortedbyTOTALS.set_index(['Continent','Year'])\n",
    "dfTOTALS_filtered_Continent_YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d1df334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Continent</th>\n",
       "      <th>State</th>\n",
       "      <th>Total_PCare</th>\n",
       "      <th>Total_CigLig</th>\n",
       "      <th>Total_Bags</th>\n",
       "      <th>Total_HF_Plast</th>\n",
       "      <th>Total_PDebris</th>\n",
       "      <th>Total_FishProd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Philippines</th>\n",
       "      <th>2018</th>\n",
       "      <td>119.98110</td>\n",
       "      <td>15.32586</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Zambales</td>\n",
       "      <td>43074</td>\n",
       "      <td>107413.0</td>\n",
       "      <td>571492</td>\n",
       "      <td>621716.0</td>\n",
       "      <td>236213.0</td>\n",
       "      <td>32919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>119.90968</td>\n",
       "      <td>15.76393</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Zambales</td>\n",
       "      <td>40815</td>\n",
       "      <td>91363.0</td>\n",
       "      <td>525644</td>\n",
       "      <td>575261.0</td>\n",
       "      <td>246275.0</td>\n",
       "      <td>31751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>120.98112</td>\n",
       "      <td>14.57938</td>\n",
       "      <td>Asia</td>\n",
       "      <td>National Capital Region</td>\n",
       "      <td>37500</td>\n",
       "      <td>22680.0</td>\n",
       "      <td>297860</td>\n",
       "      <td>29496.0</td>\n",
       "      <td>7560.0</td>\n",
       "      <td>11606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>120.98120</td>\n",
       "      <td>14.57202</td>\n",
       "      <td>Asia</td>\n",
       "      <td>National Capital Region</td>\n",
       "      <td>26155</td>\n",
       "      <td>20756.0</td>\n",
       "      <td>234609</td>\n",
       "      <td>197791.0</td>\n",
       "      <td>173515.0</td>\n",
       "      <td>31382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ghana</th>\n",
       "      <th>2016</th>\n",
       "      <td>0.01915</td>\n",
       "      <td>5.64315</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Greater Accra</td>\n",
       "      <td>25124</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>202483</td>\n",
       "      <td>711736.0</td>\n",
       "      <td>41091.0</td>\n",
       "      <td>7516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Malaysia</th>\n",
       "      <th>2018</th>\n",
       "      <td>102.13667</td>\n",
       "      <td>2.27628</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Melaka</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>102.13667</td>\n",
       "      <td>2.27628</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Melaka</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">United States</th>\n",
       "      <th>2018</th>\n",
       "      <td>-76.96442</td>\n",
       "      <td>38.89483</td>\n",
       "      <td>North America</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>-76.96442</td>\n",
       "      <td>38.89483</td>\n",
       "      <td>North America</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>-79.03804</td>\n",
       "      <td>35.75197</td>\n",
       "      <td>North America</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54388 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Longitude  Latitude      Continent  \\\n",
       "Country       Year                                       \n",
       "Philippines   2018  119.98110  15.32586           Asia   \n",
       "              2018  119.90968  15.76393           Asia   \n",
       "              2018  120.98112  14.57938           Asia   \n",
       "              2018  120.98120  14.57202           Asia   \n",
       "Ghana         2016    0.01915   5.64315         Africa   \n",
       "...                       ...       ...            ...   \n",
       "Malaysia      2018  102.13667   2.27628           Asia   \n",
       "              2018  102.13667   2.27628           Asia   \n",
       "United States 2018  -76.96442  38.89483  North America   \n",
       "              2018  -76.96442  38.89483  North America   \n",
       "              2018  -79.03804  35.75197  North America   \n",
       "\n",
       "                                      State  Total_PCare  Total_CigLig  \\\n",
       "Country       Year                                                       \n",
       "Philippines   2018                 Zambales        43074      107413.0   \n",
       "              2018                 Zambales        40815       91363.0   \n",
       "              2018  National Capital Region        37500       22680.0   \n",
       "              2018  National Capital Region        26155       20756.0   \n",
       "Ghana         2016            Greater Accra        25124       32067.0   \n",
       "...                                     ...          ...           ...   \n",
       "Malaysia      2018                   Melaka            0           0.0   \n",
       "              2018                   Melaka            0           0.0   \n",
       "United States 2018     District of Columbia            0           0.0   \n",
       "              2018     District of Columbia            0           0.0   \n",
       "              2018           North Carolina            0           0.0   \n",
       "\n",
       "                    Total_Bags  Total_HF_Plast  Total_PDebris  Total_FishProd  \n",
       "Country       Year                                                             \n",
       "Philippines   2018      571492        621716.0       236213.0           32919  \n",
       "              2018      525644        575261.0       246275.0           31751  \n",
       "              2018      297860         29496.0         7560.0           11606  \n",
       "              2018      234609        197791.0       173515.0           31382  \n",
       "Ghana         2016      202483        711736.0        41091.0            7516  \n",
       "...                        ...             ...            ...             ...  \n",
       "Malaysia      2018           0             0.0            0.0               0  \n",
       "              2018           0             0.0            0.0               0  \n",
       "United States 2018           0             0.0            0.0               0  \n",
       "              2018           0             0.0            0.0               0  \n",
       "              2018           0             0.0            0.0               0  \n",
       "\n",
       "[54388 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Macro Analysis 04\n",
    "# Filter by Country and Year\n",
    "dfTOTALS_filtered_Country_YY = dfsortedbyTOTALS.set_index(['Country','Year'])\n",
    "dfTOTALS_filtered_Country_YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce265bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Adress</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total_PCare</th>\n",
       "      <th>Total_CigLig</th>\n",
       "      <th>Total_Bags</th>\n",
       "      <th>Total_HF_Plast</th>\n",
       "      <th>Total_PDebris</th>\n",
       "      <th>Total_FishProd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-123.435585</td>\n",
       "      <td>38.690549</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Blackpoint Beach</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-123.484406</td>\n",
       "      <td>38.728707</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Dune Drift Beach</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-123.456400</td>\n",
       "      <td>38.713200</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Ohlson Beach</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-123.490915</td>\n",
       "      <td>38.735105</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Walk On Beach</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-124.462100</td>\n",
       "      <td>42.714900</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Rocky Point</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54383</th>\n",
       "      <td>-124.100770</td>\n",
       "      <td>41.252420</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>NA</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54384</th>\n",
       "      <td>-124.163890</td>\n",
       "      <td>40.863150</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>NA</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54385</th>\n",
       "      <td>-124.149530</td>\n",
       "      <td>40.865560</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>NA</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>305.0</td>\n",
       "      <td>95</td>\n",
       "      <td>150.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54386</th>\n",
       "      <td>-124.126110</td>\n",
       "      <td>40.959180</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>NA</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54387</th>\n",
       "      <td>-124.132120</td>\n",
       "      <td>40.934250</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>NA</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>29</td>\n",
       "      <td>16.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54388 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Longitude   Latitude      Continent        Country       State  \\\n",
       "0     -123.435585  38.690549  North America  United States  California   \n",
       "1     -123.484406  38.728707  North America  United States  California   \n",
       "2     -123.456400  38.713200  North America  United States  California   \n",
       "3     -123.490915  38.735105  North America  United States  California   \n",
       "4     -124.462100  42.714900  North America  United States      Oregon   \n",
       "...           ...        ...            ...            ...         ...   \n",
       "54383 -124.100770  41.252420  North America  United States  California   \n",
       "54384 -124.163890  40.863150  North America  United States  California   \n",
       "54385 -124.149530  40.865560  North America  United States  California   \n",
       "54386 -124.126110  40.959180  North America  United States  California   \n",
       "54387 -124.132120  40.934250  North America  United States  California   \n",
       "\n",
       "                 Adress  Year  Total_PCare  Total_CigLig  Total_Bags  \\\n",
       "0      Blackpoint Beach  2015            0           0.0           2   \n",
       "1      Dune Drift Beach  2015            1           0.0           0   \n",
       "2          Ohlson Beach  2015            0           0.0           0   \n",
       "3         Walk On Beach  2015            0           1.0           2   \n",
       "4           Rocky Point  2015            0           4.0           0   \n",
       "...                 ...   ...          ...           ...         ...   \n",
       "54383                NA  2015            0           0.0          20   \n",
       "54384                NA  2015            0          10.0           4   \n",
       "54385                NA  2015           10         305.0          95   \n",
       "54386                NA  2015            0          48.0          28   \n",
       "54387                NA  2015            0          59.0          29   \n",
       "\n",
       "       Total_HF_Plast  Total_PDebris  Total_FishProd  \n",
       "0                 2.0           19.0               1  \n",
       "1                 1.0           15.0               0  \n",
       "2                 0.0            0.0               0  \n",
       "3                 0.0            5.0               0  \n",
       "4                 7.0          881.0               1  \n",
       "...               ...            ...             ...  \n",
       "54383             0.0            5.0              10  \n",
       "54384            18.0            2.0               4  \n",
       "54385           150.0          350.0              70  \n",
       "54386            40.0            8.0               1  \n",
       "54387            16.0           85.0               7  \n",
       "\n",
       "[54388 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Macro Analysis 05\n",
    "Subset_TOTALS = df02[['Longitude','Latitude','Continent','Country','State','Adress','Year','Total_PCare', 'Total_CigLig', 'Total_Bags', 'Total_HF_Plast', 'Total_PDebris', 'Total_FishProd']]\n",
    "Subset_TOTALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38917e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Adress</th>\n",
       "      <th>Year</th>\n",
       "      <th>HardPlasticBeverageBottle</th>\n",
       "      <th>HardOtherPlasticBottle</th>\n",
       "      <th>...</th>\n",
       "      <th>PlasticStraps</th>\n",
       "      <th>FishingGlowSticks</th>\n",
       "      <th>FishingOtherPlasticDebris</th>\n",
       "      <th>Total_PCare</th>\n",
       "      <th>Total_CigLig</th>\n",
       "      <th>Total_Bags</th>\n",
       "      <th>Total_HF_Plast</th>\n",
       "      <th>Total_PDebris</th>\n",
       "      <th>Total_FishProd</th>\n",
       "      <th>Totales_Absolutos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>13428</td>\n",
       "      <td>-100.39581</td>\n",
       "      <td>20.62067</td>\n",
       "      <td>North America</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Querétaro</td>\n",
       "      <td>NA</td>\n",
       "      <td>2016</td>\n",
       "      <td>500385</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>500385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>500385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47537</th>\n",
       "      <td>54850</td>\n",
       "      <td>119.98110</td>\n",
       "      <td>15.32586</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Zambales</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>122576</td>\n",
       "      <td>82804</td>\n",
       "      <td>...</td>\n",
       "      <td>3108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43074</td>\n",
       "      <td>107413.0</td>\n",
       "      <td>571492</td>\n",
       "      <td>621716.0</td>\n",
       "      <td>236213.0</td>\n",
       "      <td>32919</td>\n",
       "      <td>1612827.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41879</th>\n",
       "      <td>48645</td>\n",
       "      <td>119.90968</td>\n",
       "      <td>15.76393</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Zambales</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>113280</td>\n",
       "      <td>78750</td>\n",
       "      <td>...</td>\n",
       "      <td>2871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40815</td>\n",
       "      <td>91363.0</td>\n",
       "      <td>525644</td>\n",
       "      <td>575261.0</td>\n",
       "      <td>246275.0</td>\n",
       "      <td>31751</td>\n",
       "      <td>1511109.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Record  Longitude  Latitude      Continent      Country      State  \\\n",
       "11122   13428 -100.39581  20.62067  North America       Mexico  Querétaro   \n",
       "47537   54850  119.98110  15.32586           Asia  Philippines   Zambales   \n",
       "41879   48645  119.90968  15.76393           Asia  Philippines   Zambales   \n",
       "\n",
       "      Adress  Year  HardPlasticBeverageBottle  HardOtherPlasticBottle  ...  \\\n",
       "11122     NA  2016                     500385                       0  ...   \n",
       "47537     NA  2018                     122576                   82804  ...   \n",
       "41879     NA  2018                     113280                   78750  ...   \n",
       "\n",
       "       PlasticStraps  FishingGlowSticks  FishingOtherPlasticDebris  \\\n",
       "11122              0                  0                          0   \n",
       "47537           3108                  0                          0   \n",
       "41879           2871                  0                          0   \n",
       "\n",
       "       Total_PCare  Total_CigLig  Total_Bags  Total_HF_Plast  Total_PDebris  \\\n",
       "11122            0           0.0           0        500385.0            0.0   \n",
       "47537        43074      107413.0      571492        621716.0       236213.0   \n",
       "41879        40815       91363.0      525644        575261.0       246275.0   \n",
       "\n",
       "       Total_FishProd  Totales_Absolutos  \n",
       "11122               0           500385.0  \n",
       "47537           32919          1612827.0  \n",
       "41879           31751          1511109.0  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify last action commited\n",
    "plasticbottle01.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b1a05",
   "metadata": {},
   "source": [
    "### Convert List into Arrays (with Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "288d247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plasticbottlelista01 = np.array(plasticbottle01)\n",
    "plasticbottlelista02 = np.array(plasticbottle02)\n",
    "plasticbottlelista03 = np.array(plasticbottle03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f06c450f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify prior action commited\n",
    "type(plasticbottlelista01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c646ebb",
   "metadata": {},
   "source": [
    "### Stack Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9f4c8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13428, -100.39581, 20.62067, ..., 236213.0, 32919, 1612827.0],\n",
       "       [54850, 119.9811, 15.32586, ..., 246275.0, 31751, 1511109.0],\n",
       "       [48645, 119.90968, 15.76393, ..., 41091.0, 7516, 1020017.0],\n",
       "       ...,\n",
       "       [54197, -79.5305, 8.97657, ..., 182505.0, 10267, 641876.0],\n",
       "       [54840, 117.44223, 8.50225, ..., 173515.0, 31382, 684208.0],\n",
       "       [48346, -76.79695, 17.96452, ..., 127097.0, 6980, 420480.0]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plasticbottles = np.column_stack((plasticbottlelista01,plasticbottlelista02,plasticbottlelista03))\n",
    "plasticbottles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3843bd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54388 entries, 0 to 54387\n",
      "Data columns (total 40 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Record                       54388 non-null  int64  \n",
      " 1   Longitude                    54388 non-null  float64\n",
      " 2   Latitude                     54388 non-null  float64\n",
      " 3   Continent                    54388 non-null  object \n",
      " 4   Country                      54388 non-null  object \n",
      " 5   State                        54388 non-null  object \n",
      " 6   Adress                       54388 non-null  object \n",
      " 7   Year                         54388 non-null  int64  \n",
      " 8   HardPlasticBeverageBottle    54388 non-null  int64  \n",
      " 9   HardOtherPlasticBottle       54388 non-null  int64  \n",
      " 10  HardOrSoftPlasticBottleCap   54388 non-null  int64  \n",
      " 11  PlasticOrFoamFoodContainer   54388 non-null  float64\n",
      " 12  HardBucketOrCrate            54388 non-null  int64  \n",
      " 13  HardLighter                  54388 non-null  float64\n",
      " 14  OtherHardPlastic             54388 non-null  int64  \n",
      " 15  PlasticOrFoamPlatesBowlsCup  54388 non-null  int64  \n",
      " 16  HardSoftPersonalCareProduc   54388 non-null  int64  \n",
      " 17  HardSoftLollipopStickEarBu   54388 non-null  int64  \n",
      " 18  SoftBag                      54388 non-null  int64  \n",
      " 19  SoftWrapperOrLabel           54388 non-null  int64  \n",
      " 20  SoftStraw                    54388 non-null  float64\n",
      " 21  SoftOtherPlastic             54388 non-null  int64  \n",
      " 22  SoftCigaretteButts           54388 non-null  float64\n",
      " 23  SoftStringRingRibbon         54388 non-null  int64  \n",
      " 24  Fishing_Net                  54388 non-null  int64  \n",
      " 25  FishingLineLureRope          54388 non-null  int64  \n",
      " 26  Fishing_BuoysAndFloats       54388 non-null  int64  \n",
      " 27  FoamOtherPlasticDebris       54388 non-null  int64  \n",
      " 28  OtherPlasticDebris           54388 non-null  float64\n",
      " 29  SoftSheets                   54388 non-null  int64  \n",
      " 30  PlasticStraps                54388 non-null  int64  \n",
      " 31  FishingGlowSticks            54388 non-null  int64  \n",
      " 32  FishingOtherPlasticDebris    54388 non-null  int64  \n",
      " 33  Total_PCare                  54388 non-null  int64  \n",
      " 34  Total_CigLig                 54388 non-null  float64\n",
      " 35  Total_Bags                   54388 non-null  int64  \n",
      " 36  Total_HF_Plast               54388 non-null  float64\n",
      " 37  Total_PDebris                54388 non-null  float64\n",
      " 38  Total_FishProd               54388 non-null  int64  \n",
      " 39  Totales_Absolutos            54388 non-null  float64\n",
      "dtypes: float64(11), int64(25), object(4)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df02.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0916a90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Adress</th>\n",
       "      <th>Year</th>\n",
       "      <th>HardPlasticBeverageBottle</th>\n",
       "      <th>HardOtherPlasticBottle</th>\n",
       "      <th>...</th>\n",
       "      <th>PlasticStraps</th>\n",
       "      <th>FishingGlowSticks</th>\n",
       "      <th>FishingOtherPlasticDebris</th>\n",
       "      <th>Total_PCare</th>\n",
       "      <th>Total_CigLig</th>\n",
       "      <th>Total_Bags</th>\n",
       "      <th>Total_HF_Plast</th>\n",
       "      <th>Total_PDebris</th>\n",
       "      <th>Total_FishProd</th>\n",
       "      <th>Totales_Absolutos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>349</td>\n",
       "      <td>-123.435585</td>\n",
       "      <td>38.690549</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Blackpoint Beach</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>5413</td>\n",
       "      <td>-5.031618</td>\n",
       "      <td>50.465769</td>\n",
       "      <td>Europe</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>England</td>\n",
       "      <td>Mawgan Porth</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>47</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>5414</td>\n",
       "      <td>12.854800</td>\n",
       "      <td>55.856000</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Skåne</td>\n",
       "      <td>Lundåkrahamnen Dammhagen, 26135 Landskrona, Suède</td>\n",
       "      <td>2015</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>5420</td>\n",
       "      <td>-1.523722</td>\n",
       "      <td>43.528582</td>\n",
       "      <td>Europe</td>\n",
       "      <td>France</td>\n",
       "      <td>Aquitaine</td>\n",
       "      <td>La Barre</td>\n",
       "      <td>2015</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>126.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>5421</td>\n",
       "      <td>-1.202890</td>\n",
       "      <td>45.001000</td>\n",
       "      <td>Europe</td>\n",
       "      <td>France</td>\n",
       "      <td>Aquitaine</td>\n",
       "      <td>4 All?e Pierre Ortal, 33680 Lacanau, France</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25</td>\n",
       "      <td>60.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>35</td>\n",
       "      <td>451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37690</th>\n",
       "      <td>43570</td>\n",
       "      <td>-70.380660</td>\n",
       "      <td>43.463190</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>Maine</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>6</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37689</th>\n",
       "      <td>43569</td>\n",
       "      <td>-91.168170</td>\n",
       "      <td>30.421870</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37688</th>\n",
       "      <td>43568</td>\n",
       "      <td>-82.551770</td>\n",
       "      <td>27.856510</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>Florida</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29</td>\n",
       "      <td>73.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37710</th>\n",
       "      <td>43590</td>\n",
       "      <td>-87.189510</td>\n",
       "      <td>30.324010</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>Florida</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>223.0</td>\n",
       "      <td>4</td>\n",
       "      <td>104.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38009</th>\n",
       "      <td>43931</td>\n",
       "      <td>-72.558950</td>\n",
       "      <td>41.001230</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54388 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Record   Longitude   Latitude      Continent         Country  \\\n",
       "0         349 -123.435585  38.690549  North America   United States   \n",
       "4435     5413   -5.031618  50.465769         Europe  United Kingdom   \n",
       "4436     5414   12.854800  55.856000         Europe          Sweden   \n",
       "4442     5420   -1.523722  43.528582         Europe          France   \n",
       "4443     5421   -1.202890  45.001000         Europe          France   \n",
       "...       ...         ...        ...            ...             ...   \n",
       "37690   43570  -70.380660  43.463190  North America   United States   \n",
       "37689   43569  -91.168170  30.421870  North America   United States   \n",
       "37688   43568  -82.551770  27.856510  North America   United States   \n",
       "37710   43590  -87.189510  30.324010  North America   United States   \n",
       "38009   43931  -72.558950  41.001230  North America   United States   \n",
       "\n",
       "            State                                             Adress  Year  \\\n",
       "0      California                                   Blackpoint Beach  2015   \n",
       "4435      England                                       Mawgan Porth  2015   \n",
       "4436        Skåne  Lundåkrahamnen Dammhagen, 26135 Landskrona, Suède  2015   \n",
       "4442    Aquitaine                                           La Barre  2015   \n",
       "4443    Aquitaine        4 All?e Pierre Ortal, 33680 Lacanau, France  2015   \n",
       "...           ...                                                ...   ...   \n",
       "37690       Maine                                                 NA  2018   \n",
       "37689   Louisiana                                                 NA  2018   \n",
       "37688     Florida                                                 NA  2018   \n",
       "37710     Florida                                                 NA  2018   \n",
       "38009    New York                                                 NA  2018   \n",
       "\n",
       "       HardPlasticBeverageBottle  HardOtherPlasticBottle  ...  PlasticStraps  \\\n",
       "0                              1                       0  ...              0   \n",
       "4435                           0                       3  ...              3   \n",
       "4436                          50                       0  ...              0   \n",
       "4442                          76                       0  ...              0   \n",
       "4443                           0                       0  ...              0   \n",
       "...                          ...                     ...  ...            ...   \n",
       "37690                          0                       0  ...              0   \n",
       "37689                          6                       0  ...              0   \n",
       "37688                         15                       0  ...              0   \n",
       "37710                          1                       0  ...              0   \n",
       "38009                          0                       0  ...              0   \n",
       "\n",
       "       FishingGlowSticks  FishingOtherPlasticDebris  Total_PCare  \\\n",
       "0                      0                          0            0   \n",
       "4435                   0                          0            0   \n",
       "4436                   0                          0            0   \n",
       "4442                   0                          0           16   \n",
       "4443                   0                          1            0   \n",
       "...                  ...                        ...          ...   \n",
       "37690                  0                          0            0   \n",
       "37689                  0                          0            2   \n",
       "37688                  0                          0            0   \n",
       "37710                  0                          0            1   \n",
       "38009                  0                          0            0   \n",
       "\n",
       "       Total_CigLig  Total_Bags  Total_HF_Plast  Total_PDebris  \\\n",
       "0               0.0           2             2.0           19.0   \n",
       "4435            1.0           6            10.0           81.0   \n",
       "4436            0.0          10            60.0           50.0   \n",
       "4442            1.0          22           126.0          937.0   \n",
       "4443           20.0          25            60.0          311.0   \n",
       "...             ...         ...             ...            ...   \n",
       "37690          56.0           4             4.0           49.0   \n",
       "37689           1.0          11            17.0           24.0   \n",
       "37688          26.0          29            73.0           45.0   \n",
       "37710         223.0           4           104.0           49.0   \n",
       "38009           0.0           0             0.0            0.0   \n",
       "\n",
       "       Total_FishProd  Totales_Absolutos  \n",
       "0                   1               24.0  \n",
       "4435               47              145.0  \n",
       "4436                0              120.0  \n",
       "4442               39             1141.0  \n",
       "4443               35              451.0  \n",
       "...               ...                ...  \n",
       "37690               6              119.0  \n",
       "37689               0               55.0  \n",
       "37688               5              178.0  \n",
       "37710               1              382.0  \n",
       "38009               0                0.0  \n",
       "\n",
       "[54388 rows x 40 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorted by Date:\n",
    "dfsortedbydate = df02.sort_values(['Year'])\n",
    "dfsortedbydate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f6f57e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Adress</th>\n",
       "      <th>Year</th>\n",
       "      <th>HardPlasticBeverageBottle</th>\n",
       "      <th>HardOtherPlasticBottle</th>\n",
       "      <th>...</th>\n",
       "      <th>PlasticStraps</th>\n",
       "      <th>FishingGlowSticks</th>\n",
       "      <th>FishingOtherPlasticDebris</th>\n",
       "      <th>Total_PCare</th>\n",
       "      <th>Total_CigLig</th>\n",
       "      <th>Total_Bags</th>\n",
       "      <th>Total_HF_Plast</th>\n",
       "      <th>Total_PDebris</th>\n",
       "      <th>Total_FishProd</th>\n",
       "      <th>Totales_Absolutos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44001</th>\n",
       "      <td>51042</td>\n",
       "      <td>3.08381</td>\n",
       "      <td>36.73636</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Alger</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>3360</td>\n",
       "      <td>2.20266</td>\n",
       "      <td>36.61160</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Tipaza</td>\n",
       "      <td>PLAGE TIZIRINE CHERCHELL, 42100 Cherchell, Alg...</td>\n",
       "      <td>2015</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>3477</td>\n",
       "      <td>2.20224</td>\n",
       "      <td>36.62160</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>Tipaza</td>\n",
       "      <td>Mr Belkheira Mohammed Cite 20 Aout 1955 Bt /P ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3335.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>45</td>\n",
       "      <td>3590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25242</th>\n",
       "      <td>29245</td>\n",
       "      <td>-23.51632</td>\n",
       "      <td>14.90296</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Cabo Verde</td>\n",
       "      <td>Praia</td>\n",
       "      <td>NA</td>\n",
       "      <td>2017</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134</td>\n",
       "      <td>161.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>24</td>\n",
       "      <td>621.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36018</th>\n",
       "      <td>41481</td>\n",
       "      <td>-24.98783</td>\n",
       "      <td>16.89366</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Cabo Verde</td>\n",
       "      <td>São Vicente</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50403</th>\n",
       "      <td>57724</td>\n",
       "      <td>-71.64049</td>\n",
       "      <td>10.74462</td>\n",
       "      <td>South America</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Zulia</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>100</td>\n",
       "      <td>656</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50404</th>\n",
       "      <td>57725</td>\n",
       "      <td>-71.66144</td>\n",
       "      <td>10.76681</td>\n",
       "      <td>South America</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Zulia</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>86</td>\n",
       "      <td>284.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>61</td>\n",
       "      <td>548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50405</th>\n",
       "      <td>57726</td>\n",
       "      <td>-71.59065</td>\n",
       "      <td>10.66022</td>\n",
       "      <td>South America</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Zulia</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>1040</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>11.0</td>\n",
       "      <td>177</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50406</th>\n",
       "      <td>57727</td>\n",
       "      <td>-71.59678</td>\n",
       "      <td>10.68916</td>\n",
       "      <td>South America</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Zulia</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>381</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>126</td>\n",
       "      <td>1324.0</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50407</th>\n",
       "      <td>57728</td>\n",
       "      <td>-71.59545</td>\n",
       "      <td>10.68478</td>\n",
       "      <td>South America</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Zulia</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>458</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>59.0</td>\n",
       "      <td>686</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>25</td>\n",
       "      <td>5254.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54388 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Record  Longitude  Latitude      Continent     Country        State  \\\n",
       "44001   51042    3.08381  36.73636         Africa     Algeria        Alger   \n",
       "2495     3360    2.20266  36.61160         Africa     Algeria       Tipaza   \n",
       "2606     3477    2.20224  36.62160         Africa     Algeria       Tipaza   \n",
       "25242   29245  -23.51632  14.90296         Africa  Cabo Verde        Praia   \n",
       "36018   41481  -24.98783  16.89366         Africa  Cabo Verde  São Vicente   \n",
       "...       ...        ...       ...            ...         ...          ...   \n",
       "50403   57724  -71.64049  10.74462  South America   Venezuela        Zulia   \n",
       "50404   57725  -71.66144  10.76681  South America   Venezuela        Zulia   \n",
       "50405   57726  -71.59065  10.66022  South America   Venezuela        Zulia   \n",
       "50406   57727  -71.59678  10.68916  South America   Venezuela        Zulia   \n",
       "50407   57728  -71.59545  10.68478  South America   Venezuela        Zulia   \n",
       "\n",
       "                                                  Adress  Year  \\\n",
       "44001                                                 NA  2018   \n",
       "2495   PLAGE TIZIRINE CHERCHELL, 42100 Cherchell, Alg...  2015   \n",
       "2606   Mr Belkheira Mohammed Cite 20 Aout 1955 Bt /P ...  2016   \n",
       "25242                                                 NA  2017   \n",
       "36018                                                 NA  2018   \n",
       "...                                                  ...   ...   \n",
       "50403                                                 NA  2018   \n",
       "50404                                                 NA  2018   \n",
       "50405                                                 NA  2018   \n",
       "50406                                                 NA  2018   \n",
       "50407                                                 NA  2018   \n",
       "\n",
       "       HardPlasticBeverageBottle  HardOtherPlasticBottle  ...  PlasticStraps  \\\n",
       "44001                          0                       0  ...              0   \n",
       "2495                         900                       0  ...              0   \n",
       "2606                        3000                       0  ...              0   \n",
       "25242                         37                       0  ...             12   \n",
       "36018                          1                       0  ...              0   \n",
       "...                          ...                     ...  ...            ...   \n",
       "50403                        100                     656  ...              0   \n",
       "50404                         43                      22  ...              4   \n",
       "50405                       1040                     160  ...              8   \n",
       "50406                        381                      14  ...              0   \n",
       "50407                        458                      94  ...              0   \n",
       "\n",
       "       FishingGlowSticks  FishingOtherPlasticDebris  Total_PCare  \\\n",
       "44001                  0                          0            0   \n",
       "2495                   0                          0           40   \n",
       "2606                   0                         10           20   \n",
       "25242                  0                          0            2   \n",
       "36018                  0                          0            0   \n",
       "...                  ...                        ...          ...   \n",
       "50403                  0                          0            0   \n",
       "50404                  0                          0           12   \n",
       "50405                  0                          0           14   \n",
       "50406                  0                          0            0   \n",
       "50407                  0                          0           45   \n",
       "\n",
       "       Total_CigLig  Total_Bags  Total_HF_Plast  Total_PDebris  \\\n",
       "44001           0.0           0             0.0            1.0   \n",
       "2495           70.0        1100          1510.0          400.0   \n",
       "2606            5.0         100          3335.0           85.0   \n",
       "25242           0.0         134           161.0          300.0   \n",
       "36018           1.0           1             1.0            0.0   \n",
       "...             ...         ...             ...            ...   \n",
       "50403           0.0         156          1939.0         1527.0   \n",
       "50404          24.0          86           284.0           81.0   \n",
       "50405          11.0         177          2160.0          356.0   \n",
       "50406           4.0         126          1324.0         1282.0   \n",
       "50407          59.0         686          3504.0          935.0   \n",
       "\n",
       "       Total_FishProd  Totales_Absolutos  \n",
       "44001               0                1.0  \n",
       "2495                0             3120.0  \n",
       "2606               45             3590.0  \n",
       "25242              24              621.0  \n",
       "36018               0                3.0  \n",
       "...               ...                ...  \n",
       "50403               2             3624.0  \n",
       "50404              61              548.0  \n",
       "50405              22             2740.0  \n",
       "50406               1             2737.0  \n",
       "50407              25             5254.0  \n",
       "\n",
       "[54388 rows x 40 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorted by Continent/Country/State\n",
    "dfsortedbyGeo = df02.sort_values(['Continent', 'Country', 'State'])\n",
    "dfsortedbyGeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75ed7202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Record</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Adress</th>\n",
       "      <th>Year</th>\n",
       "      <th>HardPlasticBeverageBottle</th>\n",
       "      <th>HardOtherPlasticBottle</th>\n",
       "      <th>...</th>\n",
       "      <th>PlasticStraps</th>\n",
       "      <th>FishingGlowSticks</th>\n",
       "      <th>FishingOtherPlasticDebris</th>\n",
       "      <th>Total_PCare</th>\n",
       "      <th>Total_CigLig</th>\n",
       "      <th>Total_Bags</th>\n",
       "      <th>Total_HF_Plast</th>\n",
       "      <th>Total_PDebris</th>\n",
       "      <th>Total_FishProd</th>\n",
       "      <th>Totales_Absolutos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>13428</td>\n",
       "      <td>-100.39581</td>\n",
       "      <td>20.62067</td>\n",
       "      <td>North America</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Querétaro</td>\n",
       "      <td>NA</td>\n",
       "      <td>2016</td>\n",
       "      <td>500385</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>500385.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>500385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47537</th>\n",
       "      <td>54850</td>\n",
       "      <td>119.98110</td>\n",
       "      <td>15.32586</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Zambales</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>122576</td>\n",
       "      <td>82804</td>\n",
       "      <td>...</td>\n",
       "      <td>3108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43074</td>\n",
       "      <td>107413.0</td>\n",
       "      <td>571492</td>\n",
       "      <td>621716.0</td>\n",
       "      <td>236213.0</td>\n",
       "      <td>32919</td>\n",
       "      <td>1612827.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41879</th>\n",
       "      <td>48645</td>\n",
       "      <td>119.90968</td>\n",
       "      <td>15.76393</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Zambales</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>113280</td>\n",
       "      <td>78750</td>\n",
       "      <td>...</td>\n",
       "      <td>2871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40815</td>\n",
       "      <td>91363.0</td>\n",
       "      <td>525644</td>\n",
       "      <td>575261.0</td>\n",
       "      <td>246275.0</td>\n",
       "      <td>31751</td>\n",
       "      <td>1511109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11413</th>\n",
       "      <td>13720</td>\n",
       "      <td>0.01915</td>\n",
       "      <td>5.64315</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Greater Accra</td>\n",
       "      <td>NA</td>\n",
       "      <td>2016</td>\n",
       "      <td>76741</td>\n",
       "      <td>90246</td>\n",
       "      <td>...</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25124</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>202483</td>\n",
       "      <td>711736.0</td>\n",
       "      <td>41091.0</td>\n",
       "      <td>7516</td>\n",
       "      <td>1020017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24628</th>\n",
       "      <td>28562</td>\n",
       "      <td>-80.44189</td>\n",
       "      <td>8.64607</td>\n",
       "      <td>North America</td>\n",
       "      <td>Panama</td>\n",
       "      <td>Coclé</td>\n",
       "      <td>NA</td>\n",
       "      <td>2017</td>\n",
       "      <td>60000</td>\n",
       "      <td>3574</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>380.0</td>\n",
       "      <td>7898</td>\n",
       "      <td>70517.0</td>\n",
       "      <td>14720.0</td>\n",
       "      <td>3605</td>\n",
       "      <td>97411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50138</th>\n",
       "      <td>57457</td>\n",
       "      <td>102.13667</td>\n",
       "      <td>2.27628</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Melaka</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50139</th>\n",
       "      <td>57458</td>\n",
       "      <td>102.13667</td>\n",
       "      <td>2.27628</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>Melaka</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53031</th>\n",
       "      <td>60356</td>\n",
       "      <td>-76.96442</td>\n",
       "      <td>38.89483</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53032</th>\n",
       "      <td>60357</td>\n",
       "      <td>-76.96442</td>\n",
       "      <td>38.89483</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53704</th>\n",
       "      <td>61031</td>\n",
       "      <td>-79.03804</td>\n",
       "      <td>35.75197</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>NA</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54388 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Record  Longitude  Latitude      Continent        Country  \\\n",
       "11122   13428 -100.39581  20.62067  North America         Mexico   \n",
       "47537   54850  119.98110  15.32586           Asia    Philippines   \n",
       "41879   48645  119.90968  15.76393           Asia    Philippines   \n",
       "11413   13720    0.01915   5.64315         Africa          Ghana   \n",
       "24628   28562  -80.44189   8.64607  North America         Panama   \n",
       "...       ...        ...       ...            ...            ...   \n",
       "50138   57457  102.13667   2.27628           Asia       Malaysia   \n",
       "50139   57458  102.13667   2.27628           Asia       Malaysia   \n",
       "53031   60356  -76.96442  38.89483  North America  United States   \n",
       "53032   60357  -76.96442  38.89483  North America  United States   \n",
       "53704   61031  -79.03804  35.75197  North America  United States   \n",
       "\n",
       "                      State Adress  Year  HardPlasticBeverageBottle  \\\n",
       "11122             Querétaro     NA  2016                     500385   \n",
       "47537              Zambales     NA  2018                     122576   \n",
       "41879              Zambales     NA  2018                     113280   \n",
       "11413         Greater Accra     NA  2016                      76741   \n",
       "24628                 Coclé     NA  2017                      60000   \n",
       "...                     ...    ...   ...                        ...   \n",
       "50138                Melaka     NA  2018                          0   \n",
       "50139                Melaka     NA  2018                          0   \n",
       "53031  District of Columbia     NA  2018                          0   \n",
       "53032  District of Columbia     NA  2018                          0   \n",
       "53704        North Carolina     NA  2018                          0   \n",
       "\n",
       "       HardOtherPlasticBottle  ...  PlasticStraps  FishingGlowSticks  \\\n",
       "11122                       0  ...              0                  0   \n",
       "47537                   82804  ...           3108                  0   \n",
       "41879                   78750  ...           2871                  0   \n",
       "11413                   90246  ...            609                  0   \n",
       "24628                    3574  ...            117                  0   \n",
       "...                       ...  ...            ...                ...   \n",
       "50138                       0  ...              0                  0   \n",
       "50139                       0  ...              0                  0   \n",
       "53031                       0  ...              0                  0   \n",
       "53032                       0  ...              0                  0   \n",
       "53704                       0  ...              0                  0   \n",
       "\n",
       "       FishingOtherPlasticDebris  Total_PCare  Total_CigLig  Total_Bags  \\\n",
       "11122                          0            0           0.0           0   \n",
       "47537                          0        43074      107413.0      571492   \n",
       "41879                          0        40815       91363.0      525644   \n",
       "11413                          0        25124       32067.0      202483   \n",
       "24628                          0          291         380.0        7898   \n",
       "...                          ...          ...           ...         ...   \n",
       "50138                          0            0           0.0           0   \n",
       "50139                          0            0           0.0           0   \n",
       "53031                          0            0           0.0           0   \n",
       "53032                          0            0           0.0           0   \n",
       "53704                          0            0           0.0           0   \n",
       "\n",
       "       Total_HF_Plast  Total_PDebris  Total_FishProd  Totales_Absolutos  \n",
       "11122        500385.0            0.0               0           500385.0  \n",
       "47537        621716.0       236213.0           32919          1612827.0  \n",
       "41879        575261.0       246275.0           31751          1511109.0  \n",
       "11413        711736.0        41091.0            7516          1020017.0  \n",
       "24628         70517.0        14720.0            3605            97411.0  \n",
       "...               ...            ...             ...                ...  \n",
       "50138             0.0            0.0               0                0.0  \n",
       "50139             0.0            0.0               0                0.0  \n",
       "53031             0.0            0.0               0                0.0  \n",
       "53032             0.0            0.0               0                0.0  \n",
       "53704             0.0            0.0               0                0.0  \n",
       "\n",
       "[54388 rows x 40 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorted by Categories (Figures ASC/DESC)\n",
    "dfsortedbyCategories = df02.sort_values(by=['HardPlasticBeverageBottle', 'HardOtherPlasticBottle',\n",
    "       'HardOrSoftPlasticBottleCap', 'PlasticOrFoamFoodContainer',\n",
    "       'HardBucketOrCrate', 'HardLighter', 'OtherHardPlastic',\n",
    "       'PlasticOrFoamPlatesBowlsCup', 'HardSoftPersonalCareProduc',\n",
    "       'HardSoftLollipopStickEarBu', 'SoftBag', 'SoftWrapperOrLabel',\n",
    "       'SoftStraw', 'SoftOtherPlastic', 'SoftCigaretteButts',\n",
    "       'SoftStringRingRibbon', 'Fishing_Net', 'FishingLineLureRope',\n",
    "       'Fishing_BuoysAndFloats', 'FoamOtherPlasticDebris',\n",
    "       'OtherPlasticDebris',\"SoftSheets\",\"PlasticStraps\",\"FishingGlowSticks\",\"FishingOtherPlasticDebris\"],\n",
    "                                        ascending=False)\n",
    "dfsortedbyCategories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b2d1c",
   "metadata": {},
   "source": [
    "### Summarize Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "be10e84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Total_PDebris' 'Total_FishProd' 'Total_HF_P' 'Total_Bags'\n",
      " 'Total_CigLig ' 'Total_HealthCare']\n",
      "12087685.0\n",
      "11079490\n",
      "1723788\n",
      "82868549.0\n",
      "687821\n"
     ]
    }
   ],
   "source": [
    "Total_HealthCare = df02['Total_PCare'].sum()\n",
    "Total_CigLig = df02['Total_CigLig'].sum()\n",
    "Total_Bags = df02['Total_Bags'].sum()\n",
    "Total_HF_P = df02['Total_HF_Plast'].sum()\n",
    "Total_FishProd = df02['Total_FishProd'].sum()\n",
    "Total_PDebris = df02['Total_PDebris'].sum()\n",
    "Final_Summary = np.array(['Total_PDebris','Total_FishProd','Total_HF_P','Total_Bags','Total_CigLig ','Total_HealthCare'])\n",
    "print(Final_Summary)\n",
    "print(Total_CigLig)\n",
    "print(Total_Bags)\n",
    "print(Total_FishProd)\n",
    "print(Total_PDebris)\n",
    "print(Total_HealthCare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a05ab71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Total_PDebris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e43b9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$82868549.0\n"
     ]
    }
   ],
   "source": [
    "print('$ ' + str(Total_PDebris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b54d57d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_PDebris amount is: 82868549.0\n",
      "Total_FishProd amount is: 1723788\n",
      "Total_HF_P amount is: 19545031.0\n",
      "Total_Bags amount is: 11079490\n",
      "Total_CigLig amount is: 12087685.0\n",
      "Total_HealthCare amount is: 19545031.0\n"
     ]
    }
   ],
   "source": [
    "print('Total_PDebris amount is: ' + str(Total_PDebris))\n",
    "print('Total_FishProd amount is: ' + str(Total_FishProd))\n",
    "print('Total_HF_P amount is: ' + str(Total_HF_P))\n",
    "print('Total_Bags amount is: ' + str(Total_Bags))\n",
    "print('Total_CigLig amount is: ' + str(Total_CigLig))\n",
    "print('Total_HealthCare amount is: ' + str(Total_HF_P))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac7e11",
   "metadata": {},
   "source": [
    "### Arrays (Vectors) with Numpy\n",
    "####### https://numpy.org/doc/stable/user/absolute_beginners.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "#### ARRAYS aka VECTORS\n",
    "# =============================================================\n",
    "# With respect to Python, a vector is a one-dimensional array of lists.\n",
    "\n",
    "#### UNIDIMENSIONAL Arrays\n",
    "array_01 = np.array([1,2,3,4,5])\n",
    "arr = np.array([2, 1, 5, 3, 7, 4, 6, 8])\n",
    "\n",
    "#### Array_Dimension (shape)\n",
    "array_01.shape\n",
    "\n",
    "#### Array_Dimension (size)\n",
    "array_01.size\n",
    "\n",
    "#### Sort Arrays\n",
    "np.sort(arr)\n",
    "\n",
    "#### Array_Indexes\n",
    "array_01[0]\n",
    "print(\"Hello\", \"...this is are the results after computing today´s workload:\", array_01[1], array_01[4])\n",
    "array_01[-1]\n",
    "\n",
    "# Create Custom Arrays\n",
    "array_empty = np.zeros((3,3))\n",
    "array_ones = np.ones((3,3))\n",
    "array_full = np.full((3,3), 5)\n",
    "array_random = np.random.randn(10,4)\n",
    "arraylinspace= np.linspace(0, 10, num=5)\n",
    "arraylinspace\n",
    "\n",
    "#### Optimizing byte_datasize\n",
    "arrayint64 = np.ones(2, dtype=np.int64)\n",
    "arrayint64.dtype\n",
    "arrayint64 = np.ones(2, dtype=np.int32)\n",
    "arrayint64.dtype\n",
    "arrayint64 = np.ones(2, dtype=np.int16)\n",
    "arrayint64.dtype\n",
    "\n",
    "#### Define a random array with (np.ceil and np.floor)\n",
    "b = np.array([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0])\n",
    "b\n",
    "c = np.ceil(b)\n",
    "c\n",
    "d = np.floor(b)\n",
    "d\n",
    "\n",
    "#### Extract the nearest int which is closer to zero (np.trunc)\n",
    "e = np.trunc(b)\n",
    "e\n",
    "\n",
    "#### Round elements of the array to the nearest integer. (np.rint)\n",
    "f = np.rint(b)\n",
    "f\n",
    "\n",
    "#### Round to nearest integer towards zero.\n",
    "g = np.fix(3.14)\n",
    "g\n",
    "\n",
    "#### Evenly round to the given number of decimals.\n",
    "h = np.round(16.055, 2)\n",
    "h\n",
    "\n",
    "i = np.around([0.37, 1.64], decimals=1)\n",
    "i\n",
    "\n",
    "j = np.around([.5, 1.5, 2.5, 3.5, 4.5]) # rounds to nearest even value\n",
    "j\n",
    "\n",
    "k = np.around([1,2,3,11], decimals=-1)\n",
    "k\n",
    "\n",
    "\n",
    "#### BIDIMENSIONAL Arrays\n",
    "calificaciones = np.array(\n",
    "    [\n",
    "    [60,80,83,80,69,70],\n",
    "    [0.10, 0.10, 0.10, 0.20, 0.20, 0.30]\n",
    "    ]\n",
    "    )\n",
    "\n",
    "calificaciones.shape\n",
    "\n",
    "#### Bidimensional Arrays composed by a sequence of values (arange) \n",
    "array_02 = np.arange(1,16)\n",
    "\n",
    "#### Reshaping_Array_Dimensions (reshape)\n",
    "array_03 = array_02.reshape(3,5)\n",
    "\n",
    "#### Arrays composed by random values (randbetween)\n",
    "# Lets create a pair of arrays with randbetween values (1000 values, 2 decimals)\n",
    "x = np.round(np.random.normal(1.5, 0.05, 1000), 2)\n",
    "y = np.round(np.random.normal(50.1, 5, 1000), 1)\n",
    "\n",
    "#### Locate values in Bidimensional Arrays\n",
    "\n",
    "# Locate values as follows: < : >(on both arrays), positions 2 and 3 (range 2-4)\n",
    "calificaciones[:,2:4]  \n",
    "# Display <0> (array 0), <:> all values\n",
    "notas2 = calificaciones[0,:]\n",
    "\n",
    "#### Merge Arrays\n",
    "# Condition: Arrays must share the same dimensions\n",
    "xy = np.column_stack((x,y))\n",
    "\n",
    "#### Convert Array_Values from one type to another (dtype)\n",
    "array_floats= array_01 = np.array([1,2,3,4,5], dtype=float)\n",
    "\n",
    "#### Convert Lists into Arrays\n",
    "# 01 Lets begin defining a pair of lists\n",
    "Notas = [60,80,83,80,69,70]\n",
    "Porcentaje = [0.10, 0.10, 0.10, 0.20, 0.20, 0.30]\n",
    "# 02 Convert into Arrays\n",
    "np_notas = np.array(Notas)\n",
    "np_porcentaje = np.array(Porcentaje)\n",
    "\n",
    "#### Convert Arrays into DataFrames\n",
    "# Arrays contain similar types of objects or elements whereas DataFrame can have objects or multiple or similar data types.\n",
    "\n",
    "## Numpy to pandas\n",
    "h = np.array([[1,2],[3,4]])\n",
    "df_h = pd.DataFrame(h)\n",
    "print(df_h)\n",
    "## Pandas to numpy\n",
    "df_h_n = np.array(df_h)\n",
    "print(df_h_n)\n",
    "\n",
    "#### Create Random List\n",
    "#  Parameters: 10 random values, conditions = Min=1, Max=6)\n",
    "rolls = np.random.randint(low=1, high=6, size=10)\n",
    "rolls\n",
    "type(rolls)\n",
    "print(dir(rolls))\n",
    "help(rolls.mean)\n",
    "rolls.mean()\n",
    "\n",
    "#### Convert an Array into a List\n",
    "rolls.tolist()\n",
    "\n",
    "#### Arrays Arithmetical Ops \n",
    "a = np_notas[np_notas > 80]\n",
    "\n",
    "# Multiplicar las notas x los %\n",
    "desglose_promedio = np_notas * np_porcentaje\n",
    "\n",
    "# Utilizamos la funcion Sum para validar la suma de la matriz\n",
    "Nota_Final = sum(desglose_promedio)\n",
    "print(sum(desglose_promedio))\n",
    "\n",
    "#### Find dissimilar objects (setdiff1d)\n",
    "# Lets create a apair of arrays:\n",
    "d = np.array([1,2,3,4,5,6,7,8])\n",
    "e = np.array([1,2,3,6,7,8])\n",
    "# \n",
    "f = np.setdiff1d(d,e)\n",
    "print(f)\n",
    "\n",
    "#### Find homologous (counterpart) values (intersect1d)\n",
    "g = np.intersect1d(d,e)\n",
    "print(g)\n",
    "\n",
    "#### Encode / Decode\n",
    "\n",
    "import base64\n",
    "\n",
    "# 01. Encode\n",
    "encoded = base64.b64encode(b'Hello')\n",
    "print(encoded)\n",
    "# 02. Decode\n",
    "data = base64.b64decode(encoded)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca1d19",
   "metadata": {},
   "source": [
    "# STAGE 5: Data Publishing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0111277",
   "metadata": {},
   "source": [
    "By this time, all the steps are completed and the data is ready for analytics. All that’s left is to publish the newly Wrangled Data in a place where it can be easily accessed and used by you and other stakeholders. \n",
    "\n",
    "You can deposit the data into a new architecture or database. As long as you completed the other processes correctly, the final output of your efforts will be high-quality data that you use to gain insights, create business reports, and more. \n",
    "\n",
    "You might even further process the data to create larger and more complex data structures such as Data Warehouses. At this point, the possibilities are endless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4dae56",
   "metadata": {},
   "source": [
    "### Writing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc61161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.to_csv(\"C:\\\\Users\\\\Asus VivoBook\\\\Dropbox\\\\My PC (DESKTOP-GN5CQHE)\\\\Desktop\\\\Documentos\\\\The Vault\\\\Python\\\\PyWD\\\\test_Output.csv'\") \n",
    "# You can also setup additional customizations as follows: \n",
    "    # Omit header and add delimiters: \n",
    "        # df.to_csv(\"c:/tmp/courses.csv\", header=False, sep='|')\n",
    "    # Append the DataFrame to an existing CSV File:\n",
    "        # df.to_csv(\"c:/tmp/courses.csv\", header=False, sep='|', index=False, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f877fc8",
   "metadata": {},
   "source": [
    "### Pushing Jupyter Notebooks in Github/Gitlab\n",
    "\n",
    "To save Jupyter Notebooks in GitHub automatically, you can follow these general steps:\n",
    "\n",
    "Create a new repository in your GitHub account to store your Jupyter Notebooks.\n",
    "\n",
    "Install Git on your computer if it's not already installed.\n",
    "\n",
    "Open the Jupyter Notebook that you want to save to GitHub.\n",
    "\n",
    "In Jupyter, go to the \"File\" menu and select \"Save As\".\n",
    "\n",
    "Choose a location on your computer to save the notebook and give it a name.\n",
    "\n",
    "Open a terminal or command prompt and navigate to the directory where you saved the notebook.\n",
    "\n",
    "Initialize a Git repository in this directory using the command \"git init\".\n",
    "\n",
    "Add the notebook file to the Git repository using the command \"git add <filename>\".\n",
    "\n",
    "Commit the changes using the command \"git commit -m 'Initial commit'\" or any other descriptive message.\n",
    "\n",
    "Link the local Git repository with the remote GitHub repository using the command \"git remote add origin <remote repository URL>\".\n",
    "\n",
    "Push the changes to the remote repository using the command \"git push -u origin master\" or \"git push\" if the branch is already created.\n",
    "\n",
    "After following these steps, your Jupyter Notebook should be saved to your GitHub repository automatically. Whenever you make changes to the notebook, you can simply add, commit and push those changes to GitHub.\n",
    "    \n",
    "###### Copyright: https://chat.openai.com/chat , Feb-19-2023 , 20:34 CST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23255f57",
   "metadata": {},
   "source": [
    "# Annexes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae3a516",
   "metadata": {},
   "source": [
    "### 01. Data Wrangling Best Practices\n",
    "https://hevodata.com/learn/data-wrangling/#s2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f781c",
   "metadata": {},
   "source": [
    "### Help Function - help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(pd))\n",
    "help(pd.__loader__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523635f8",
   "metadata": {},
   "source": [
    "### Print Function - print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e4a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello world')\n",
    "\n",
    "print('hello', 'world', sep=None)\n",
    "\n",
    "print('hello', 'world', sep=' ')\n",
    "\n",
    "print('hello', 'world')\n",
    "\n",
    "print('hello', 'world', sep='\\n')\n",
    "\n",
    "print('home', 'user', 'documents', sep='/')\n",
    "\n",
    "print(*['jdoe is', 42, 'years old'])\n",
    "\n",
    "print('line1\\nline2\\nline3')\n",
    "\n",
    "value = print('hello world')\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b5632",
   "metadata": {},
   "source": [
    "### Type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a49f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two ways about how to consult the Data Type, lets see the difference\n",
    "type(df_America['Loan Status'])\n",
    "type(df_America[['Loan Status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5cdf8a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
